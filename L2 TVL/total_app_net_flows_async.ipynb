{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ffefb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as r\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta, date\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import asyncio, aiohttp, nest_asyncio\n",
    "from aiohttp_retry import RetryClient, ExponentialRetry\n",
    "nest_asyncio.apply()\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:71.0) Gecko/20100101 Firefox/71.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "539f29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/23267409/how-to-implement-retry-mechanism-into-python-requests-library\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "s = requests.Session()\n",
    "retries = Retry(total=10, backoff_factor=1, status_forcelist=[ 502, 503, 504 ])\n",
    "s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "pwd = os.getcwd()\n",
    "if 'L2 TVL' in pwd:\n",
    "    prepend = ''\n",
    "else:\n",
    "    prepend = 'L2 TVL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "bbc56e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "trailing_num_days = 90\n",
    "\n",
    "start_date = date.today()-timedelta(days=trailing_num_days +1)\n",
    "\n",
    "# start_date = datetime.strptime('2022-07-13', '%Y-%m-%d').date()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d984f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all apps > 10 m tvl\n",
    "min_tvl = 10_000_000\n",
    "all_api = 'https://api.llama.fi/protocols'\n",
    "res = pd.DataFrame( r.get(all_api, headers=header).json() )\n",
    "res = res[res['tvl'] > min_tvl] ##greater than 10mil\n",
    "res = res[res['category'] != 'CEX'] #centralized exchanges\n",
    "res = res[res['category'] != 'Chain'] #chain staking (i.e. polygon, stacks, xdai)\n",
    "\n",
    "# cats = res['category'].drop_duplicates()\n",
    "# display(cats)\n",
    "# print(len(res))\n",
    "# print(res.columns)\n",
    "# display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "17b3c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "beebc582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_13814/266227638.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "protocols = res[['slug','chainTvls']]\n",
    "# print(protocols)\n",
    "re = res['chainTvls']\n",
    "# r[1].keys()\n",
    "protocols['chainTvls'] = protocols['chainTvls'].apply(lambda x: list(x.keys()) )\n",
    "# protocols = protocols.head()\n",
    "# protocols[protocols['chainTvls'].map(set(['Arbitrum']).issubset)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c84c9ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protocols = protocols[ protocols['slug'] == 'uniswap-v3' ]\n",
    "# api_str = 'https://api.llama.fi/protocol/'\n",
    "# ad = pd.DataFrame( r.get(api_str).json()['chainTvls'] ).T[['tokens']]\n",
    "# ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9717e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_str = 'https://api.llama.fi/protocol/uniswap'\n",
    "# prot_req = r.get(api_str, headers=header).json()['chainTvls']\n",
    "# # prot_req['Ethereum']\n",
    "# prot_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4e4e981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = {x for x in range(100, 600)}\n",
    "statuses.remove(200)\n",
    "statuses.remove(429)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "052b6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_tvl(apistring, header, statuses, chains, prot):\n",
    "        prod = []\n",
    "        retry_client = RetryClient()\n",
    "        async with retry_client.get(apistring, retry_options=ExponentialRetry(attempts=10), raise_for_status=statuses) as response:\n",
    "                try:\n",
    "                        prot_req = await response.json()\n",
    "                        prot_req = prot_req['chainTvls']\n",
    "                        for ch in chains:\n",
    "                                ad = pd.json_normalize( prot_req[ch]['tokens'] )\n",
    "                                ad_usd = pd.json_normalize( prot_req[ch]['tokensInUsd'] )\n",
    "                        #             ad = ad.merge(how='left')\n",
    "                                if not ad.empty:\n",
    "                                        ad = pd.melt(ad,id_vars = ['date'])\n",
    "                                        ad = ad.rename(columns={'variable':'token','value':'token_value'})\n",
    "                                        ad_usd = pd.melt(ad_usd,id_vars = ['date'])\n",
    "                                        ad_usd = ad_usd.rename(columns={'variable':'token','value':'usd_value'})\n",
    "                                        ad = ad.merge(ad_usd,on=['date','token'])\n",
    "                                        \n",
    "                                        ad['date'] = pd.to_datetime(ad['date'], unit ='s') #convert to days\n",
    "                                        ad['token'] = ad['token'].str.replace('tokens.','', regex=False)\n",
    "                                        ad['protocol'] = prot\n",
    "                                        ad['chain'] = ch\n",
    "                                #         ad['start_date'] = pd.to_datetime(prot[1])\n",
    "                                        # ad['date'] = ad['date'] - timedelta(days=1) #change to eod vs sod\n",
    "                                        prod.append(ad)\n",
    "                except Exception as e:\n",
    "                        raise Exception(\"Could not convert json\")\n",
    "        await retry_client.close()\n",
    "        \n",
    "        return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "00c9efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range(protocols):\n",
    "        data_dfs = []\n",
    "        fee_df = []\n",
    "        # for dt in date_range:\n",
    "        #         await asyncio.gather()\n",
    "        #         data_dfs.append(res_df)\n",
    "        #         # res.columns\n",
    "        # try:\n",
    "        #         loop.close()\n",
    "        # except:\n",
    "        #         #nothing\n",
    "        loop = asyncio.get_event_loop()\n",
    "        #get by app\n",
    "        api_str = 'https://api.llama.fi/protocol/'\n",
    "        # print(protocols)\n",
    "        prod = []\n",
    "        tasks = []\n",
    "        for index,proto in protocols.iterrows():\n",
    "                #     print(proto)\n",
    "                prot = proto['slug']\n",
    "                chains = proto['chainTvls']\n",
    "                apic = api_str + prot\n",
    "                #     time.sleep(0.1)\n",
    "                tasks.append( get_tvl(apic, header, statuses, chains, prot) )\n",
    "        # print(tasks)\n",
    "        data_dfs = loop.run_until_complete(asyncio.gather(*tasks, return_exceptions=True))\n",
    "        # print(date_range)\n",
    "        # loop.close()\n",
    "        # print(data_dfs)\n",
    "        # fee_df = pd.concat(data_dfs)\n",
    "        # return fee_df\n",
    "        return data_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d3399236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df = get_range(protocols)\n",
    "# print (typeof(df_df_all) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5b4e1888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for dat in df_df:\n",
    "        if isinstance(dat,list):\n",
    "                # print(dat)\n",
    "                for pt in dat: #each list within the list (i.e. multiple chains)\n",
    "                        try:\n",
    "                                tempdf = pd.DataFrame(pt)\n",
    "                                if not tempdf.empty:\n",
    "                                        # print(tempdf)\n",
    "                                        df_list.append(tempdf)\n",
    "                        except:\n",
    "                                continue\n",
    "# df_df_all = pd.DataFrame()\n",
    "df_df_all = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "bef17372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5ab956a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_13814/3407144366.py:11: FutureWarning:\n",
      "\n",
      "The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create an extra day to handle for tokens dropping to 0\n",
    "df_df_shift = df_df_all.copy()\n",
    "df_df_shift['date'] = df_df_shift['date'] + timedelta(days=1)\n",
    "df_df_shift['token_value'] = 0\n",
    "df_df_shift['usd_value'] = 0\n",
    "\n",
    "#merge back in\n",
    "df_df_all = pd.concat([df_df_all,df_df_shift])\n",
    "df_df_all = df_df_all[df_df_all['date'] <= pd.to_datetime(\"today\") ]\n",
    "\n",
    "df_df_all = df_df_all.groupby(['date','token','chain','protocol']).sum()\n",
    "df_df_all = df_df_all.reset_index()\n",
    "df_df_shift = []\n",
    "# display(df_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c7c1ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done api\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df_df_all = pd.concat(df_df_all)\n",
    "# print(df_df_all[2])\n",
    "print(\"done api\")\n",
    "# display(df_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "53c381e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: token_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [229], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m df_df \u001b[39m=\u001b[39m df_df_all[df_df_all[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mdate \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m start_date\u001b[39m-\u001b[39mtimedelta(days\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) ]\n\u001b[1;32m      4\u001b[0m \u001b[39m#trailing comp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df_df[\u001b[39m'\u001b[39m\u001b[39mlast_token_value\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_df\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mtoken\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mprotocol\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mchain\u001b[39;49m\u001b[39m'\u001b[39;49m])[\u001b[39m'\u001b[39;49m\u001b[39mtoken_value\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mshift(\u001b[39m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m#now actually filter\u001b[39;00m\n\u001b[1;32m      7\u001b[0m df_df \u001b[39m=\u001b[39m df_df[df_df[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mdate \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m start_date ]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/site-packages/pandas/core/groupby/generic.py:1415\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(key) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1407\u001b[0m     \u001b[39m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m     \u001b[39m# valid syntax, so don't raise warning\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndexing with multiple keys (implicitly converted to a tuple \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mof keys) will be deprecated, use a list instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1412\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1413\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1414\u001b[0m     )\n\u001b[0;32m-> 1415\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/site-packages/pandas/core/base.py:248\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj:\n\u001b[0;32m--> 248\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn not found: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m     subset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj[key]\n\u001b[1;32m    250\u001b[0m     ndim \u001b[39m=\u001b[39m subset\u001b[39m.\u001b[39mndim\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: token_value'"
     ]
    }
   ],
   "source": [
    "#filter down a bit so we can do trailing comp w/o doing every row\n",
    "df_df = df_df_all[df_df_all['date'].dt.date >= start_date-timedelta(days=1) ]\n",
    "\n",
    "#trailing comp\n",
    "df_df['last_token_value'] = df_df.groupby(['token','protocol','chain'])['token_value'].shift(1)\n",
    "#now actually filter\n",
    "df_df = df_df[df_df['date'].dt.date >= start_date ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf54141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = df_df[(df_df['protocol'] == 'uniswap') & (df_df['chain'] == 'Optimism')]\n",
    "# sample = sample.sort_values(by='date',ascending=False)\n",
    "# # display(sample)\n",
    "# sample.to_csv('check_uni_error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9eb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_df = df_df.copy()\n",
    "data_df = data_df.sort_values(by='date')\n",
    "# data_df['token_value'] = data_df['token_value'].replace(0, np.nan) #keep zeroes\n",
    "# price = usd value / num tokens\n",
    "data_df['price_usd'] = data_df['usd_value']/data_df['token_value']\n",
    "data_df['last_price_usd'] = data_df.groupby(['token','protocol', 'chain'])['price_usd'].shift(1)\n",
    "\n",
    "# If first instnace of token, make sure there's no price diff\n",
    "data_df['last_price_usd'] = data_df[['last_price_usd', 'price_usd']].bfill(axis=1).iloc[:, 0]\n",
    "#Forward fill if token drops off\n",
    "data_df['price_usd'] = data_df[['price_usd','last_price_usd']].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "data_df.sort_values(by='date',inplace=True)\n",
    "\n",
    "# net token change\n",
    "data_df['net_token_flow'] = data_df['token_value'] - data_df['last_token_value']\n",
    "# net token change * current price\n",
    "data_df['net_dollar_flow'] = data_df['net_token_flow'] * data_df['price_usd']\n",
    "\n",
    "\n",
    "data_df = data_df[abs(data_df['net_dollar_flow']) < 50_000_000_000] #50 bil error bar for bad prices\n",
    "data_df = data_df[~data_df['net_dollar_flow'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[(data_df['protocol']=='stargate') & (data_df['chain']=='Optimism') & (data_df['date']>='2022-10-31')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "netdf_df = data_df[['date','protocol','chain','net_dollar_flow','usd_value']]\n",
    "netdf_df = netdf_df.fillna(0)\n",
    "netdf_df = netdf_df.sort_values(by='date',ascending=True)\n",
    "netdf_df = netdf_df.groupby(['date','protocol','chain']).sum(['net_dollar_flow','usd_value']) ##agg by app\n",
    "\n",
    "#usd_value is the TVL on a given day\n",
    "netdf_df = netdf_df.groupby(['date','protocol','chain','usd_value']).sum(['net_dollar_flow'])\n",
    "netdf_df.reset_index(inplace=True)\n",
    "\n",
    "# netdf_df['cumul_net_dollar_flow'] = netdf_df[['protocol','chain','net_dollar_flow']]\\\n",
    "#                                     .groupby(['protocol','chain']).cumsum()\n",
    "# netdf_df['cumul_net_dollar_flow_7d'] = netdf_df[['protocol','chain','net_dollar_flow']]\\\n",
    "#                                     .groupby(['protocol','chain'])['net_dollar_flow'].rolling(7, min_periods=1).sum()\\\n",
    "#                                     .reset_index(drop=True)\n",
    "# netdf_df['cumul_net_dollar_flow_30d'] = netdf_df[['protocol','chain','net_dollar_flow']]\\\n",
    "#                                     .groupby(['protocol','chain'])['net_dollar_flow'].rolling(30, min_periods=1).sum()\\\n",
    "#                                     .reset_index(drop=True)\n",
    "netdf_df.reset_index(inplace=True)\n",
    "netdf_df.drop(columns=['index'],inplace=True)\n",
    "# display(netdf_df[netdf_df['protocol']=='makerdao'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# netdf_df[(netdf_df['protocol']=='stargate') & (netdf_df['chain']=='Optimism')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ccf06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latest\n",
    "netdf_df['rank_desc'] = netdf_df.groupby(['protocol', 'chain'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "# display(netdf_df[netdf_df['protocol'] == 'lyra'])\n",
    "netdf_df = netdf_df[  #( netdf_df['rank_desc'] == 1 ) &\\\n",
    "                        (~netdf_df['chain'].str.contains('-borrowed')) &\\\n",
    "                        (~netdf_df['chain'].str.contains('-staking')) &\\\n",
    "                        (~netdf_df['chain'].str.contains('-pool2')) &\\\n",
    "                            (~netdf_df['chain'].str.contains('-treasury')) &\\\n",
    "                        (~( netdf_df['chain'] == 'treasury') ) &\\\n",
    "                        (~( netdf_df['chain'] == 'borrowed') ) &\\\n",
    "                        (~( netdf_df['chain'] == 'staking') ) &\\\n",
    "                            (~( netdf_df['chain'] == 'treasury') ) &\\\n",
    "                        (~( netdf_df['chain'] == 'pool2') ) &\\\n",
    "                        (~( netdf_df['protocol'] == 'polygon-bridge-&-staking') )  &\\\n",
    "                            (~(netdf_df['protocol'].str[-4:] == '-cex') )\n",
    "#                         & (~( netdf_df['chain'] == 'Ethereum') )\n",
    "                        ]\n",
    "# display(netdf_df[netdf_df['protocol']=='makerdao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = netdf_df.copy()\n",
    "drange = [0, 1, 7, 30, 90, 180, 365]\n",
    "summary_df = summary_df.sort_values(by='date',ascending=True)\n",
    "# summary_df = summary_df[(summary_df['chain'] == 'Solana') & (summary_df['protocol'] == 'uxd')]\n",
    "for i in drange:\n",
    "        if i == 0:\n",
    "                summary_df['cumul_net_dollar_flow'] = summary_df[['protocol','chain','net_dollar_flow']]\\\n",
    "                                    .groupby(['protocol','chain']).cumsum()\n",
    "                summary_df['flow_direction'] = np.where(summary_df['cumul_net_dollar_flow']>=0,1,-1)\n",
    "                summary_df['abs_cumul_net_dollar_flow'] = abs(summary_df['cumul_net_dollar_flow'])\n",
    "        else:\n",
    "                col_str = 'cumul_net_dollar_flow_' + str(i) + 'd'\n",
    "                # print(col_str)\n",
    "                summary_df[col_str] = summary_df[['protocol','chain','net_dollar_flow']]\\\n",
    "                                    .groupby(['protocol','chain'])['net_dollar_flow'].transform(lambda x: x.rolling(i, min_periods=1).sum() )\n",
    "                                #         .rolling(i, min_periods=1).sum()\\ #This caused errors and mismatches\n",
    "                                #     .reset_index(level=0,drop=True)#.values\n",
    "                summary_df['flow_direction_' + str(i) + 'd'] = np.where(summary_df[col_str]>=0,1,-1)\n",
    "                summary_df['abs_cumul_net_dollar_flow_' + str(i) + 'd'] = abs(summary_df[col_str])\n",
    "                # display(summary_df)\n",
    "                # display(summary_df[(summary_df['chain'] == 'Optimism') & (summary_df['protocol'] == 'yearn-finance')] )\n",
    "# display(summary_df[netdf_df['protocol']=='makerdao'])\n",
    "# display(summary_df[(summary_df['chain'] == 'Optimism') & (summary_df['protocol'] == 'qidao')].iloc[-7: , :15] )\n",
    "# display(summary_df[(summary_df['protocol']=='stargate') & (summary_df['chain']=='Optimism')])\n",
    "summary_df['pct_of_tvl'] = 100* summary_df['net_dollar_flow'] / summary_df['usd_value']\n",
    "summary_df = summary_df[summary_df['rank_desc'] == 1 ]\n",
    "summary_df.to_csv('latest_tvl_app_trends.csv')\n",
    "# display(summary_df)\n",
    "for i in drange:\n",
    "        fig = ''\n",
    "        if i == 0:\n",
    "                yval = 'abs_cumul_net_dollar_flow'\n",
    "                hval = 'cumul_net_dollar_flow'\n",
    "                cval = 'flow_direction'\n",
    "                saveval = 'net_app_flows'\n",
    "                titleval = \"App Net Flows Change by App -> Chain - Last \" + str(trailing_num_days) + \\\n",
    "                            \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\"\n",
    "        else:\n",
    "                yval = 'abs_cumul_net_dollar_flow_' + str(i) +'d'\n",
    "                hval = 'cumul_net_dollar_flow_' + str(i) +'d'\n",
    "                cval = 'flow_direction_' + str(i) +'d'\n",
    "                saveval = 'net_app_flows_' + str(i) +'d'\n",
    "                titleval = \"App Net Flows Change by App -> Chain - Last \" + str(i) + \\\n",
    "                            \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\"\n",
    "        # print(yval)\n",
    "        # print(cval)\n",
    "        # print(titleval)\n",
    "        # print(hval)\n",
    "        fig = px.treemap(summary_df[summary_df[yval] !=0], \\\n",
    "                 path=[px.Constant(\"all\"), 'chain', 'protocol'], \\\n",
    "#                  path=[px.Constant(\"all\"), 'token', 'chain', 'protocol'], \\\n",
    "                 values=yval, color=cval\n",
    "#                 ,color_discrete_map={'-1':'red', '1':'green'})\n",
    "                ,color_continuous_scale='Spectral'\n",
    "                     , title = titleval\n",
    "                \n",
    "                , hover_data = [hval]\n",
    "                )\n",
    "        \n",
    "        fig.update_traces(root_color=\"lightgrey\")\n",
    "        fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "        fig.write_image(prepend + \"img_outputs/svg/\" + saveval + \".svg\") #prepend + \n",
    "        fig.write_image(prepend + \"img_outputs/png/\" + saveval + \".png\") #prepend + \n",
    "        fig.write_html(prepend + \"img_outputs/\" + saveval + \".html\", include_plotlyjs='cdn')\n",
    "# fig.data[0].textinfo = 'label+text+value'\n",
    "\n",
    "# fig.update_layout(tickprefix = '$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dabb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(summary_df[summary_df['protocol']=='makerdao'].iloc[: , :15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bdf6d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# summary_df['flow_direction'] = np.where(summary_df['cumul_net_dollar_flow']>=0,1,-1)\n",
    "# summary_df['flow_direction_7d'] = np.where(summary_df['cumul_net_dollar_flow_7d']>=0,1,-1)\n",
    "# summary_df['abs_cumul_net_dollar_flow'] = abs(summary_df['cumul_net_dollar_flow'])\n",
    "# summary_df['abs_cumul_net_dollar_flow_7d'] = abs(summary_df['cumul_net_dollar_flow_7d'])\n",
    "\n",
    "# display(summary_df)\n",
    "# print(summary_df[summary_df['chain']=='Arbitrum'])\n",
    "# print(summary_df[summary_df['chain']=='Optimism'])\n",
    "# display(summary_df)\n",
    "# fig = px.treemap(summary_df[summary_df['abs_cumul_net_dollar_flow'] !=0], \\\n",
    "#                  path=[px.Constant(\"all\"), 'chain', 'protocol'], \\\n",
    "# #                  path=[px.Constant(\"all\"), 'token', 'chain', 'protocol'], \\\n",
    "#                  values='abs_cumul_net_dollar_flow', color='flow_direction'\n",
    "# #                 ,color_discrete_map={'-1':'red', '1':'green'})\n",
    "#                 ,color_continuous_scale='Spectral'\n",
    "#                      , title = \"App Net Flows Change by App -> Chain - Last \" + str(trailing_num_days) + \\\n",
    "#                             \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\"\n",
    "                \n",
    "#                 ,hover_data=['cumul_net_dollar_flow']\n",
    "#                 )\n",
    "# # fig.data[0].textinfo = 'label+text+value'\n",
    "# fig.update_traces(root_color=\"lightgrey\")\n",
    "# fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "# # fig.update_layout(tickprefix = '$')\n",
    "\n",
    "# fig_7d = px.treemap(summary_df[summary_df['abs_cumul_net_dollar_flow_7d'] !=0], \\\n",
    "#                  path=[px.Constant(\"all\"), 'chain', 'protocol'], \\\n",
    "# #                  path=[px.Constant(\"all\"), 'token', 'chain', 'protocol'], \\\n",
    "#                  values='abs_cumul_net_dollar_flow_7d', color='flow_direction_7d'\n",
    "# #                 ,color_discrete_map={'-1':'red', '1':'green'})\n",
    "#                 ,color_continuous_scale='Spectral'\n",
    "#                      , title = \"App Net Flows Change by App -> Chain - Last \" + str(7) + \\\n",
    "#                             \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\"\n",
    "                \n",
    "#                 # ,hover_data=['cumul_net_dollar_flow_7d']\n",
    "#                 )\n",
    "# fig_7d.update_traces(root_color=\"lightgrey\")\n",
    "# fig_7d.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "# fig_7d.show()\n",
    "\n",
    "fig_app = px.treemap(summary_df[summary_df['abs_cumul_net_dollar_flow'] !=0], \\\n",
    "                #  path=[px.Constant(\"all\"), 'chain', 'protocol'], \\\n",
    "#                  path=[px.Constant(\"all\"), 'token', 'chain', 'protocol'], \\\n",
    "                        path=[px.Constant(\"all\"), 'protocol','chain'], \\\n",
    "                 values='abs_cumul_net_dollar_flow', color='flow_direction'\n",
    "#                 ,color_discrete_map={'-1':'red', '1':'green'})\n",
    "                ,color_continuous_scale='Spectral'\n",
    "                , title = \"App Net Flows Change by Chain -> App - Last \" + str(trailing_num_days) + \\\n",
    "                            \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\"\n",
    "                ,hover_data=['cumul_net_dollar_flow']\n",
    "                )\n",
    "# fig.data[0].textinfo = 'label+text+value'\n",
    "fig_app.update_traces(root_color=\"lightgrey\")\n",
    "fig_app.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c722ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.write_image(prepend + \"img_outputs/svg/net_app_flows.svg\") #prepend + \n",
    "# fig.write_image(prepend + \"img_outputs/png/net_app_flows.png\") #prepend + \n",
    "# fig.write_html(prepend + \"img_outputs/net_app_flows.html\", include_plotlyjs='cdn')\n",
    "\n",
    "# fig_7d.write_image(prepend + \"img_outputs/svg/net_app_flows_7d.svg\") #prepend + \n",
    "# fig_7d.write_image(prepend + \"img_outputs/png/net_app_flows_7d.png\") #prepend + \n",
    "# fig_7d.write_html(prepend + \"img_outputs/net_app_flows_7d.html\", include_plotlyjs='cdn')\n",
    "\n",
    "fig_app.write_image(prepend + \"img_outputs/svg/net_app_flows_by_app.svg\") #prepend + \n",
    "fig_app.write_image(prepend + \"img_outputs/png/net_app_flows_by_app.png\") #prepend + \n",
    "fig_app.write_html(prepend + \"img_outputs/net_app_flows_by_app.html\", include_plotlyjs='cdn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f573693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter nbconvert --to python total_app_net_flows_async.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('new-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d537a1638226190f579d6fbb68604c1b09ebc740a69df557abedb49ad78e592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
