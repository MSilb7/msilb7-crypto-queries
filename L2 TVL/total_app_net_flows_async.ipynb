{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as r\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta, date\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import asyncio, aiohttp, nest_asyncio\n",
    "from aiohttp_retry import RetryClient, ExponentialRetry\n",
    "import defillama_utils as dfl\n",
    "nest_asyncio.apply()\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:71.0) Gecko/20100101 Firefox/71.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/23267409/how-to-implement-retry-mechanism-into-python-requests-library\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "s = requests.Session()\n",
    "retries = Retry(total=10, backoff_factor=1, status_forcelist=[ 502, 503, 504 ])\n",
    "s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "pwd = os.getcwd()\n",
    "if 'L2 TVL' in pwd:\n",
    "    prepend = ''\n",
    "else:\n",
    "    prepend = 'L2 TVL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc56e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date ranges to build charts for\n",
    "drange = [0, 1, 7, 30, 90, 180, 365]\n",
    "# Do we count net flows marked at the lastest token price (1) or the price on each day (0)\n",
    "# By default, we opt to 1, so that price movement isn't accidentally counted as + or - flow remainder\n",
    "mark_at_latest_price = 1 #some errors with missing token prices we need to fix first (i.e. rage trade on arbi marks usdc as 0)\n",
    "\n",
    "trailing_num_days = max(drange)\n",
    "# print(trailing_num_days)\n",
    "\n",
    "start_date = date.today()-timedelta(days=trailing_num_days +1)\n",
    "print(start_date)\n",
    "\n",
    "# start_date = datetime.strptime('2022-07-13', '%Y-%m-%d').date()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b8d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all apps > 10 m tvl\n",
    "min_tvl = 10_000_000\n",
    "\n",
    "# if TVL by token is not available, do we fallback on raw TVL (sensitive to token prices)?\n",
    "is_fallback_on_raw_tvl = True#False\n",
    "\n",
    "df_df = dfl.get_all_protocol_tvls_by_chain_and_token(min_tvl, is_fallback_on_raw_tvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3254fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_df)\n",
    "df_df_all = df_df.copy()\n",
    "df_df_all.head()\n",
    "# df_df_all[df_df_all['protocol'] == 'velodrome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef17372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_df_all)\n",
    "df_df_all2 = df_df_all.copy()\n",
    "# df_df_all2['token_value'] = df_df_all2['token_value'].fillna(0)\n",
    "df_df_all2['token_value'] = df_df_all2['token_value'].astype('float64')\n",
    "df_df_all2['usd_value'] = df_df_all2['usd_value'].astype('float64')\n",
    "# display(df_df_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab956a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an extra day to handle for tokens dropping to 0\n",
    "\n",
    "print(df_df_all2.dtypes)\n",
    "\n",
    "df_df_all_u = df_df_all2.fillna(0)\n",
    "df_df_shift = df_df_all_u.copy()\n",
    "df_df_shift['date'] = df_df_shift['date'] + timedelta(days=1)\n",
    "df_df_shift['token_value'] = 0.0\n",
    "df_df_shift['usd_value'] = 0.0\n",
    "\n",
    "#merge back in\n",
    "df_df_all = pd.concat([df_df_all_u,df_df_shift])\n",
    "\n",
    "print(df_df_all.dtypes)\n",
    "\n",
    "# display(df_df_all)\n",
    "df_df_all = df_df_all[df_df_all['date'] <= pd.to_datetime(\"today\") ]\n",
    "\n",
    "df_df_all['token_value'] = df_df_all['token_value'].fillna(0)\n",
    "df_df_all = df_df_all.groupby(['date','token','chain','protocol','name','category','parent_protocol']).sum(['usd_value','token_value'])\n",
    "\n",
    "# display(df_df_all)\n",
    "df_df_all = df_df_all.reset_index()\n",
    "df_df_shift = []\n",
    "# display(df_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c1ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_df_all = pd.concat(df_df_all)\n",
    "# print(df_df_all[2])\n",
    "print(\"done api\")\n",
    "# display(df_df_all[df_df_all['protocol'] == 'velodrome'])\n",
    "# display(df_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c381e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter down a bit so we can do trailing comp w/o doing every row\n",
    "df_df = df_df_all[df_df_all['date'].dt.date >= start_date-timedelta(days=1) ]\n",
    "\n",
    "#trailing comp\n",
    "df_df['last_token_value'] = df_df.groupby(['token','protocol','chain'])['token_value'].shift(1)\n",
    "#now actually filter\n",
    "df_df = df_df[df_df['date'].dt.date >= start_date ]\n",
    "# display(df_df[df_df['protocol'] == 'velodrome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_df[(df_df['chain'] == 'Arbitrum') & (df_df['protocol'] == 'rage-trade') & (df_df['date'] > '2022-12-01')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf54141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_df)\n",
    "# sample = df_df[(df_df['protocol'] == 'uniswap') & (df_df['chain'] == 'Optimism')]\n",
    "# sample = sample.sort_values(by='date',ascending=False)\n",
    "# # display(sample)\n",
    "# sample.to_csv('check_uni_error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9eb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = df_df.copy()\n",
    "data_df = data_df.sort_values(by='date')\n",
    "# data_df['token_value'] = data_df['token_value'].replace(0, np.nan) #keep zeroes\n",
    "# price = usd value / num tokens\n",
    "data_df['price_usd'] = data_df['usd_value']/data_df['token_value']\n",
    "data_df['last_price_usd'] = data_df.groupby(['token','protocol', 'chain'])['price_usd'].shift(1)\n",
    "\n",
    "# If first instnace of token, make sure there's no price diff\n",
    "data_df['last_price_usd'] = data_df[['last_price_usd', 'price_usd']].bfill(axis=1).iloc[:, 0]\n",
    "#Forward fill if token drops off\n",
    "data_df['price_usd'] = data_df[['price_usd','last_price_usd']].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "data_df.sample(20)\n",
    "# display(data_df[data_df['protocol'] == 'velodrome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['token_rank_desc'] = data_df.groupby(['chain','token'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "data_df['token_rank_desc_prot'] = data_df.groupby(['chain','token','protocol'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "\n",
    "data_df['token_rank_desc_prot_gt0'] = data_df.query('token_value > 0')\\\n",
    "                                    .groupby(['chain', 'token', 'protocol'])['date']\\\n",
    "                                    .rank(method='first', ascending=False)\n",
    "\n",
    "# get latest price either by protocol or in aggregate\n",
    "# if we don't have a match by protocol, then select in aggregate.\n",
    "\n",
    "latest_prices_df_raw_prot = data_df[~data_df['price_usd'].isna()][['token','chain','protocol','price_usd']][data_df['token_rank_desc_prot'] ==1]\n",
    "latest_prices_df_raw = data_df[~data_df['price_usd'].isna()][['token','chain','price_usd']][data_df['token_rank_desc'] ==1]\n",
    "latest_prices_df_raw_prot_gt0 = data_df[~data_df['price_usd'].isna()][['token','chain','price_usd','protocol']][data_df['token_rank_desc_prot_gt0'] ==1]\n",
    "\n",
    "latest_prices_df_prot = latest_prices_df_raw_prot.groupby(['token','chain','protocol']).median('price_usd')\n",
    "latest_prices_df_prot = latest_prices_df_prot.rename(columns={'price_usd':'latest_price_usd_prot'})\n",
    "\n",
    "latest_prices_df = latest_prices_df_raw.groupby(['token','chain']).median('price_usd')\n",
    "latest_prices_df = latest_prices_df.rename(columns={'price_usd':'latest_price_usd_raw'})\n",
    "\n",
    "latest_prices_df_prot_gt0 = latest_prices_df_raw_prot_gt0.groupby(['token','chain','protocol']).median('price_usd')\n",
    "latest_prices_df_prot_gt0 = latest_prices_df_prot_gt0.rename(columns={'price_usd':'latest_price_usd_prot_gt0'})\n",
    "\n",
    "latest_prices_df_prot = latest_prices_df_prot.reset_index()\n",
    "latest_prices_df = latest_prices_df.reset_index()\n",
    "latest_prices_df_prot_gt0 = latest_prices_df_prot_gt0.reset_index()\n",
    "\n",
    "prices_df = data_df[['chain','protocol','token']].drop_duplicates()\n",
    "prices_df = prices_df.merge(latest_prices_df_prot,on=['token','chain','protocol'], how='left')\n",
    "prices_df = prices_df.merge(latest_prices_df,on=['token','chain'], how='left')\n",
    "prices_df = prices_df.merge(latest_prices_df_prot_gt0,on=['token','chain','protocol'], how='left')\n",
    "prices_df['latest_price_usd'] = \\\n",
    "        prices_df['latest_price_usd_prot'].where(prices_df['latest_price_usd_prot'] > 0, \\\n",
    "        prices_df['latest_price_usd_raw'].where(prices_df['latest_price_usd_raw'] > 0, \\\n",
    "        prices_df['latest_price_usd_prot_gt0']))\n",
    "    # prices_df.loc[prices_df[['latest_price_usd_prot', 'latest_price_usd_raw', 'latest_price_usd_prot_gt0']].first_valid_index()]\n",
    "# prices_df['latest_price_usd'] = prices_df['latest_price_usd_prot'].combine_first(prices_df['latest_price_usd_raw'])\n",
    "\n",
    "prices_df = prices_df[['chain','protocol','token','latest_price_usd']]#,'latest_price_usd_prot','latest_price_usd_raw','latest_price_usd_prot_gt0']]\n",
    "\n",
    "# display(prices_df)\n",
    "prices_df = prices_df[~prices_df['latest_price_usd'].isna()]\n",
    "\n",
    "\n",
    "data_df = data_df.merge(prices_df,on=['token','chain','protocol'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df[(data_df['protocol'] == 'concentrator') & (data_df['token'] == 'FXS') ]\n",
    "# prices_df[(prices_df['protocol'] == 'concentrator') & (prices_df['token'] == 'FXS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb437d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_prices_df_prot_gt0[latest_prices_df_prot_gt0['token'] == 'FXS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc58adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sort_values(by='date',inplace=True)\n",
    "\n",
    "# net token change\n",
    "data_df['net_token_flow'] = data_df['token_value'] - data_df['last_token_value']\n",
    "# net token change * current price\n",
    "data_df['net_dollar_flow'] = data_df['net_token_flow'] * data_df['price_usd']\n",
    "# net token change * latest price\n",
    "data_df['net_dollar_flow_latest_price'] = data_df['net_token_flow'] * data_df['latest_price_usd']\n",
    "\n",
    "\n",
    "data_df = data_df[abs(data_df['net_dollar_flow']) < 50_000_000_000] #50 bil error bar for bad prices\n",
    "data_df = data_df[~data_df['net_dollar_flow'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74651c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df[(data_df['protocol']=='shibaswap') & (data_df['chain']=='Ethereum') & (data_df['date'] == '2022-12-09')].sort_values(by='net_dollar_flow_latest_price',ascending=False)\n",
    "\n",
    "# data_df[data_df['protocol'] == 'velodrome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "netdf_df = data_df[['date','protocol','chain','name','category','parent_protocol','net_dollar_flow','usd_value','net_dollar_flow_latest_price']]\n",
    "netdf_df = netdf_df.fillna(0)\n",
    "netdf_df = netdf_df.sort_values(by='date',ascending=True)\n",
    "netdf_df = netdf_df.groupby(['date','protocol','chain','name','category','parent_protocol']).sum(['net_dollar_flow','usd_value','net_dollar_flow_latest_price']) ##agg by app\n",
    "\n",
    "#usd_value is the TVL on a given day\n",
    "netdf_df = netdf_df.groupby(['date','protocol','chain','usd_value','name','category','parent_protocol']).sum(['net_dollar_flow','net_dollar_flow_latest_price'])\n",
    "netdf_df.reset_index(inplace=True)\n",
    "\n",
    "# netdf_df['cumul_net_dollar_flow'] = netdf_df[['protocol','chain','net_dollar_flow']]\\\n",
    "#                                     .groupby(['protocol','chain']).cumsum()\n",
    "# netdf_df['cumul_net_dollar_flow_7d'] = netdf_df[['protocol','chain','net_dollar_flow']]\\\n",
    "#                                     .groupby(['protocol','chain'])['net_dollar_flow'].rolling(7, min_periods=1).sum()\\\n",
    "#                                     .reset_index(drop=True)\n",
    "# netdf_df['cumul_net_dollar_flow_30d'] = netdf_df[['protocol','chain','net_dollar_flow']]\\\n",
    "#                                     .groupby(['protocol','chain'])['net_dollar_flow'].rolling(30, min_periods=1).sum()\\\n",
    "#                                     .reset_index(drop=True)\n",
    "netdf_df.reset_index(inplace=True)\n",
    "netdf_df.drop(columns=['index'],inplace=True)\n",
    "# display(netdf_df[netdf_df['protocol']=='makerdao'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = netdf_df[(netdf_df['protocol']=='rage-trade') & (netdf_df['chain']=='Arbitrum') & (netdf_df['date'] > '2022-12-01')]\n",
    "# tmp.to_csv('check.csv')\n",
    "# netdf_df[(netdf_df['protocol']=='shibaswap') & (netdf_df['chain']=='Ethereum') & (netdf_df['date'] > '2022-12-01')]\n",
    "\n",
    "# netdf_df[netdf_df['protocol'] == 'velodrome'].groupby('protocol').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ccf06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latest\n",
    "netdf_df['rank_desc'] = netdf_df.groupby(['protocol', 'chain'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "# display(netdf_df[netdf_df['protocol'] == 'lyra'])\n",
    "netdf_df = netdf_df[  #( netdf_df['rank_desc'] == 1 ) &\\\n",
    "                        (~netdf_df['chain'].str.contains('-borrowed')) &\\\n",
    "                        (~netdf_df['chain'].str.contains('-staking')) &\\\n",
    "                        (~netdf_df['chain'].str.contains('-pool2')) &\\\n",
    "                            (~netdf_df['chain'].str.contains('-treasury')) &\\\n",
    "                        (~( netdf_df['chain'] == 'treasury') ) &\\\n",
    "                        (~( netdf_df['chain'] == 'borrowed') ) &\\\n",
    "                        (~( netdf_df['chain'] == 'staking') ) &\\\n",
    "                            (~( netdf_df['chain'] == 'treasury') ) &\\\n",
    "                        (~( netdf_df['chain'] == 'pool2') ) &\\\n",
    "                        (~( netdf_df['protocol'] == 'polygon-bridge-&-staking') )  &\\\n",
    "                            (~(netdf_df['protocol'].str[-4:] == '-cex') )\n",
    "#                         & (~( netdf_df['chain'] == 'Ethereum') )\n",
    "                        ]\n",
    "# display(netdf_df[netdf_df['protocol']=='makerdao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(netdf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = netdf_df.copy()\n",
    "\n",
    "summary_df = summary_df.sort_values(by='date',ascending=True)\n",
    "\n",
    "# Mark at latest price if chosen\n",
    "if mark_at_latest_price == 1:\n",
    "        summary_df['mark_at_latest_price'] = mark_at_latest_price\n",
    "        summary_df['net_dollar_flow'] = summary_df['net_dollar_flow_latest_price']\n",
    "        titleval_append = ' - At Latest Prices'\n",
    "else:\n",
    "        titleval_append = ''\n",
    "\n",
    "# summary_df = summary_df[(summary_df['chain'] == 'Solana') & (summary_df['protocol'] == 'uxd')]\n",
    "for i in drange:\n",
    "        if i == 0:\n",
    "                summary_df['cumul_net_dollar_flow'] = summary_df[['protocol','chain','net_dollar_flow']]\\\n",
    "                                    .groupby(['protocol','chain']).cumsum()\n",
    "                summary_df['flow_direction'] = np.where(summary_df['cumul_net_dollar_flow']*1.0 >= 0, 1,-1)\n",
    "                summary_df['abs_cumul_net_dollar_flow'] = abs(summary_df['cumul_net_dollar_flow'])\n",
    "                #latest price\n",
    "                \n",
    "                # display(summary_df)\n",
    "        else:\n",
    "                col_str = 'cumul_net_dollar_flow_' + str(i) + 'd'\n",
    "                tvl_str = 'daily_avg_tvl_' + str(i) + 'd'\n",
    "                # print(col_str)\n",
    "                # summary_df[col_str] = summary_df[['protocol','chain','net_dollar_flow']]\\\n",
    "                #                     .groupby(['protocol','chain'])['net_dollar_flow'].transform(lambda x: x.rolling(i, min_periods=1).sum() )\n",
    "                #chatgpt version\n",
    "                summary_df[col_str] = summary_df.groupby(['protocol','chain'])['net_dollar_flow']\\\n",
    "                                        .apply(lambda x: x.rolling(i, min_periods=1).sum())\n",
    "\n",
    "                summary_df[tvl_str] = summary_df[['protocol','chain','usd_value']]\\\n",
    "                                    .groupby(['protocol','chain'])['usd_value'].transform(lambda x: x.rolling(i, min_periods=1).mean() )\n",
    "                \n",
    "                summary_df['flow_direction_' + str(i) + 'd'] = np.where(summary_df[col_str]*1.0 >= 0, 1, -1)\n",
    "                summary_df['abs_cumul_net_dollar_flow_' + str(i) + 'd'] = abs(summary_df[col_str])\n",
    "                # display(summary_df)\n",
    "                # display(summary_df[(summary_df['chain'] == 'Optimism') & (summary_df['protocol'] == 'yearn-finance')] )\n",
    "# display(summary_df[netdf_df['protocol']=='makerdao'])\n",
    "# display(summary_df[(summary_df['chain'] == 'Optimism') & (summary_df['protocol'] == 'qidao')].iloc[-7: , :15] )\n",
    "# display(summary_df[(summary_df['protocol']=='stargate') & (summary_df['chain']=='Optimism')])\n",
    "summary_df['pct_of_tvl'] = 100* summary_df['net_dollar_flow'] / summary_df['usd_value']\n",
    "final_summary_df = summary_df[(summary_df['rank_desc'] == 1) & (summary_df['date'] >= pd.to_datetime(\"today\") -timedelta(days=7))]\n",
    "final_summary_df = final_summary_df[final_summary_df['cumul_net_dollar_flow']< 1e20] #weird error handling\n",
    "\n",
    "\n",
    "os.makedirs('csv_outputs', exist_ok=True)  \n",
    "final_summary_df.to_csv('csv_outputs/latest_tvl_app_trends.csv')  \n",
    "\n",
    "# display(summary_df)\n",
    "for i in drange:\n",
    "        fig = ''\n",
    "        if i == 0:\n",
    "                yval = 'abs_cumul_net_dollar_flow'\n",
    "                hval = 'cumul_net_dollar_flow'\n",
    "                cval = 'flow_direction'\n",
    "                saveval = 'net_app_flows'\n",
    "                titleval = \"App Net Flows Change by App -> Chain - Last \" + str(trailing_num_days) + \\\n",
    "                            \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\" + titleval_append\n",
    "        else:\n",
    "                yval = 'abs_cumul_net_dollar_flow_' + str(i) +'d'\n",
    "                hval = 'cumul_net_dollar_flow_' + str(i) +'d'\n",
    "                cval = 'flow_direction_' + str(i) +'d'\n",
    "                saveval = 'net_app_flows_' + str(i) +'d'\n",
    "                titleval = \"App Net Flows Change by App -> Chain - Last \" + str(i) + \\\n",
    "                            \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\" + titleval_append\n",
    "        # print(yval)\n",
    "        # print(cval)\n",
    "        # print(titleval)\n",
    "        # print(hval)\n",
    "        fig = px.treemap(final_summary_df[final_summary_df[yval] !=0], \\\n",
    "                 path=[px.Constant(\"all\"), 'chain', 'protocol'], \\\n",
    "#                  path=[px.Constant(\"all\"), 'token', 'chain', 'protocol'], \\\n",
    "                 values=yval, color=cval\n",
    "#                 ,color_discrete_map={'-1':'red', '1':'green'})\n",
    "                ,color_continuous_scale='Spectral'\n",
    "                     , title = titleval\n",
    "                \n",
    "                , hover_data = [hval]\n",
    "                )\n",
    "        \n",
    "        fig.update_traces(root_color=\"lightgrey\")\n",
    "        fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "        fig.write_image(prepend + \"img_outputs/svg/\" + saveval + \".svg\") #prepend + \n",
    "        fig.write_image(prepend + \"img_outputs/png/\" + saveval + \".png\") #prepend + \n",
    "        fig.write_html(prepend + \"img_outputs/\" + saveval + \".html\", include_plotlyjs='cdn')\n",
    "        if i == 30:\n",
    "                fig.show()\n",
    "# fig.data[0].textinfo = 'label+text+value'\n",
    "# fig.update_layout(tickprefix = '$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display( summary_df[(summary_df['chain'] == 'Arbitrum') & (summary_df['protocol'] == 'rage-trade') & (summary_df['rank_desc'] < 30)][['date','usd_value','protocol','net_dollar_flow','cumul_net_dollar_flow_30d']])\n",
    "\n",
    "#test sample\n",
    "summary_df[summary_df['protocol'] == 'velodrome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dabb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test_df= netdf_df[(netdf_df['chain'] == 'Arbitrum') & (netdf_df['protocol'] == 'rage-trade')][['chain','protocol','date','net_dollar_flow','rank_desc']]\n",
    "# test_df = test_df.sort_values(by='date',ascending=True)\n",
    "# test_df['test'] = test_df[['protocol','chain','net_dollar_flow']]\\\n",
    "#     .groupby(['protocol','chain'])['net_dollar_flow'].transform(lambda x: x.rolling(30, min_periods=1).sum() )\n",
    "# display(test_df[test_df['rank_desc'] < 45])\n",
    "# # display(summary_df[summary_df['protocol']=='makerdao'].iloc[: , :15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bdf6d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig_app = px.treemap(final_summary_df[final_summary_df['abs_cumul_net_dollar_flow'] !=0], \\\n",
    "                #  path=[px.Constant(\"all\"), 'chain', 'protocol'], \\\n",
    "#                  path=[px.Constant(\"all\"), 'token', 'chain', 'protocol'], \\\n",
    "                        path=[px.Constant(\"all\"), 'protocol','chain'], \\\n",
    "                 values='abs_cumul_net_dollar_flow', color='flow_direction'\n",
    "#                 ,color_discrete_map={'-1':'red', '1':'green'})\n",
    "                ,color_continuous_scale='Spectral'\n",
    "                , title = \"App Net Flows Change by Chain -> App - Last \" + str(trailing_num_days) + \\\n",
    "                            \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\"\n",
    "                ,hover_data=['cumul_net_dollar_flow']\n",
    "                )\n",
    "# fig.data[0].textinfo = 'label+text+value'\n",
    "fig_app.update_traces(root_color=\"lightgrey\")\n",
    "fig_app.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c722ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_app.write_image(prepend + \"img_outputs/svg/net_app_flows_by_app.svg\") #prepend + \n",
    "fig_app.write_image(prepend + \"img_outputs/png/net_app_flows_by_app.png\") #prepend + \n",
    "fig_app.write_html(prepend + \"img_outputs/net_app_flows_by_app.html\", include_plotlyjs='cdn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f573693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter nbconvert --to python total_app_net_flows_async.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d537a1638226190f579d6fbb68604c1b09ebc740a69df557abedb49ad78e592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
