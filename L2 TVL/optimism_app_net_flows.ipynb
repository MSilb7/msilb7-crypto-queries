{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas\n",
    "# ! pip install requests\n",
    "# ! pip install plotly\n",
    "# ! pip install datetime\n",
    "# ! pip install os\n",
    "# ! pip freeze = requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as r\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import optimism_pool_tvls as subg\n",
    "import defillama_utils as dfl\n",
    "import pandas_utils as pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "if 'L2 TVL' in pwd:\n",
    "    prepend = ''\n",
    "else:\n",
    "    prepend = 'L2 TVL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocol Incentive Start Dates\n",
    "# Eventually, move this to its own file / csv\n",
    "protocols = pd.DataFrame(\n",
    "    [\n",
    "        # name, incentive start date\n",
    "            # General Programs\n",
    "             [1,'velodrome',  3000000,          '2022-07-13',   '2022-11-17',   '', 'Partner Fund', 'defillama','']\n",
    "            ,[1,'pooltogether',   450000, '2022-07-22',   '', '', 'Partner Fund', 'defillama','']\n",
    "            ,[1,'lyra',   3000000,               '2022-08-02',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'rubicon',    900000,            '2022-07-15',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'perpetual-protocol', 9000000, '2022-07-14',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'thales', 900000,             '2022-07-15',   '',   '', 'Gov Fund - Phase 0', 'defillama',''] #TVL not relevant\n",
    "            ,[1,'aave-v3',    5000000,            '2022-08-04',   '2022-11-04',   'Aave - Liquidity Mining', 'Partner Fund', 'defillama','']\n",
    "            ,[1,'wepiggy',    300000,            '2022-08-03',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'stargate',   1000000,           '2022-08-05',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'pika-protocol',  900000,      '2022-08-29',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'pickle', 200000,             '2022-09-09',   '',   '', 'Gov Fund - Season 1', 'defillama','']\n",
    "            ,[1,'aelin',  900000,              '2022-09-12',   '2022-09-14',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'polynomial-protocol',    900000, '2022-09-14',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'xtoken', 900000,             '2022-09-19',   '',   '', 'Gov Fund - Season 1', 'defillama','']\n",
    "            ,[1,'hop-protocol',   1000000,       '2022-09-22',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'beethoven-x',    500000,        '2022-09-29',   '',   '', 'Gov Fund - Season 1', 'defillama','']\n",
    "            ,[1,'beefy',  650000*.5,              '2022-10-24',   '',   '', 'Gov Fund - Season 1', 'defillama',''] #Incenvitived VELO - Seems like Beefy boost started Oct 24? Unclear\n",
    "            ,[1,'hundred-finance',    300000,    '2022-11-28',   '',   '', 'Gov Fund - Season 1', 'defillama','']\n",
    "            ,[1,'dforce',    300000,    '2022-11-30',   '',   '', 'Gov Fund - Season 1', 'defillama','']\n",
    "            ,[1,'cbridge',    300000,    '2022-08-13',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            #Uniswap LM Program\n",
    "            ,[0,'uniswap-v3', 150000,         '2022-10-26',   '2022-11-21',   'Uniswap LM - Phase 1', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,[1,'arrakis-finance',    50000,    '2022-10-26',   '2022-11-21',   'Uniswap LM - Phase 1', 'Gov Fund - Phase 0','defillama','']\n",
    "            ,[1,'gamma',    50000,              '2022-10-26',   '2022-11-21',   'Uniswap LM - Phase 1', 'Gov Fund - Phase 0','defillama','']\n",
    "            ,[1,'xtoken',    50000,             '2022-10-26',   '2022-11-21',   'Uniswap LM - Phase 1', 'Gov Fund - Phase 0','defillama','']\n",
    "            # Other DEX Programs\n",
    "            ,[0,'synthetix',  9000000,    '2022-08-25',   '',   'All Synthetix Curve Pools', 'Gov Fund - Phase 0', 'pool-subgraph-curve',['0x7bc5728bc2b59b45a58d9a576e2ffc5f0505b35e','0x061b87122ed14b9526a813209c8a59a633257bab']] # susd/usd + seth/eth Curve incentives started\n",
    "            ,[1,'synthetix',  2*20000* (abs(pd.to_datetime(\"today\")-pd.to_datetime('2022-08-25')).days / 7 ),    '2022-08-25',   '',   'sUSD-3Crv: Curve', 'Gov Fund - Phase 0', 'pool-subgraph-curve',['0x061b87122ed14b9526a813209c8a59a633257bab']] # susd/usd + seth/eth Curve incentives started\n",
    "            ,[1,'synthetix',  20000* (abs(pd.to_datetime(\"today\")-pd.to_datetime('2022-08-25')).days / 7 ),    '2022-08-25',   '',   'sETH-ETH: Curve', 'Gov Fund - Phase 0', 'pool-subgraph-curve',['0x7bc5728bc2b59b45a58d9a576e2ffc5f0505b35e']] # susd/usd + seth/eth Curve incentives started\n",
    "            \n",
    "            ,[0,'synthetix',  3*10000* (abs(pd.to_datetime(\"today\")-pd.to_datetime('2022-09-27')).days / 7 ),    '2022-09-27',   '',   'All Synthetix Velo Pools', 'Gov Fund - Phase 0', 'pool-subgraph-velodrome',['0x9056eb7ca982a5dd65a584189994e6a27318067d' \\\n",
    "                                                                                                                                                                                                    ,'0xd16232ad60188b68076a235c65d692090caba155'\\\n",
    "                                                                                                                                                                                                    ,'0xfd7fddfc0a729ecf45fb6b12fa3b71a575e1966f']] # Velo incentives started\n",
    "            ,[1,'synthetix',  10000* (abs(pd.to_datetime(\"today\")-pd.to_datetime('2022-09-27')).days / 7 ),    '2022-09-27',   '',   'USDC/SNX: Velo', 'Gov Fund - Phase 0', 'pool-subgraph-velodrome',['0x9056eb7ca982a5dd65a584189994e6a27318067d']] # Velo incentives started\n",
    "            ,[1,'synthetix',  10000* (abs(pd.to_datetime(\"today\")-pd.to_datetime('2022-09-27')).days / 7 ),    '2022-09-27',   '',   'USDC/sUSD: Velo', 'Gov Fund - Phase 0', 'pool-subgraph-velodrome',['0xd16232ad60188b68076a235c65d692090caba155']] # Velo incentives started\n",
    "            ,[1,'synthetix',  10000* (abs(pd.to_datetime(\"today\")-pd.to_datetime('2022-09-27')).days / 7 ),    '2022-09-27',   '',   'ETH/sETH: Velo', 'Gov Fund - Phase 0', 'pool-subgraph-velodrome',['0xfd7fddfc0a729ecf45fb6b12fa3b71a575e1966f']] # Velo incentives started\n",
    "\n",
    "            ,[1,'synthetix',  18000* (abs(pd.to_datetime(\"today\")-pd.to_datetime('2022-10-25')).days / 7*4 ),    '2022-10-25',   '',   'SNX Bridge: Hop', 'Gov Fund - Phase 0', 'pool-defillama-hop',['SNX']] # Hop incentives started\n",
    "            \n",
    "            ,[1,'l2dao',  300000,    '2022-07-20',   '2022-08-22',   'L2DAO/OP: Velodrome', 'Gov Fund - Phase 0', 'subgraph-velodrome',['0xfc77e39de40e54f820e313039207dc850e4c9e60']] # l2dao/op incentives - estimating end date based on last distribution to Velo gauge + 7 days\n",
    "            ,[1,'beefy',  650000*.35,    '2022-09-13',   '',   'BIFI/OP: Velodrome', 'Gov Fund - Phase 0', 'subgraph-velodrome',['0x81f638e5d063618fc5f6a976e48e9b803b3240c0']] # bifi/op incentives\n",
    "            # Season 2\n",
    "            ,[1,'velodrome',  4000000,  '2022-11-24',   '',   'Velodrome #2 (Tour de OP)', 'Gov Fund - Season 2', 'defillama','']\n",
    "            ,[1,'revert-compoundor',  240000,  '2022-11-03',   '',   '', 'Gov Fund - Season 2', 'defillama','']\n",
    "            ]\n",
    "        , columns = ['include_in_summary','protocol','num_op','start_date', 'end_date','name', 'op_source', 'data_source','contracts']\n",
    "    )\n",
    "# print(protocols[0])\n",
    "protocols['id_format'] = protocols['protocol'].str.replace('-',' ').str.title()\n",
    "\n",
    "date_cols = ['start_date', 'end_date']\n",
    "for d in date_cols:\n",
    "    protocols[d] = pd.to_datetime( protocols[d] )\n",
    "    \n",
    "protocols['id_format'] = protocols['protocol'].str.replace('-',' ').str.title()\n",
    "\n",
    "# protocols['program_name'] = np.where( protocols['name'] == '', protocols['id_format'], protocols['name'])\n",
    "protocols['coalesce'] = np.where( protocols['name'] == ''\n",
    "                                    , protocols['id_format']\n",
    "                                    , protocols['name']\n",
    "                                    )\n",
    "# Get count by coalesced name\n",
    "pcounts = pd.DataFrame( protocols.groupby(['coalesce'])['name'].count() )\n",
    "pcounts = pcounts.rename(columns={'name':'count'})\n",
    "\n",
    "protocols = protocols.merge(pcounts, on = 'coalesce')\n",
    "\n",
    "\n",
    "protocols['program_name'] = np.where( ( (protocols['name'] == '') )#| (protocols['count'] == 1) )\n",
    "                                    , protocols['id_format']\n",
    "                                    , protocols['id_format'] + ' - ' + protocols['name']\n",
    "                                    )\n",
    "\n",
    "protocols = protocols.sort_values(by='start_date', ascending=True)\n",
    "                    \n",
    "# display(protocols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3399236",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_str = 'https://api.llama.fi/protocol/'\n",
    "\n",
    "prod = []\n",
    "s = r.Session()\n",
    "\n",
    "dfl_protocols = protocols[protocols['data_source'] == 'defillama'].copy()\n",
    "\n",
    "dfl_slugs = dfl_protocols[['protocol']].drop_duplicates()\n",
    "dfl_slugs = dfl_slugs.rename(columns={'protocol':'slug'})\n",
    "df_dfl = dfl.get_range(dfl_slugs[['slug']],['Optimism'])\n",
    "\n",
    "df_dfl = df_dfl.merge(dfl_protocols, on ='protocol')\n",
    "\n",
    "df_dfl = df_dfl[['date', 'token', 'token_value', 'usd_value', 'protocol', 'start_date','end_date','program_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d797655",
   "metadata": {},
   "outputs": [],
   "source": [
    "subg_protocols = protocols[protocols['data_source'].str.contains('pool-')].copy()\n",
    "subg_protocols['og_protocol'] = subg_protocols['protocol']\n",
    "subg_protocols['protocol'] = subg_protocols['data_source'].str.split('-').str[-1]\n",
    "# display(subg_protocols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dfs_sub = []\n",
    "for index, program in subg_protocols.iterrows():\n",
    "        for c in program['contracts']:\n",
    "                if program['protocol'] == 'curve':\n",
    "                        sdf = subg.get_curve_pool_tvl(c)\n",
    "                elif program['protocol'] == 'velodrome':\n",
    "                        sdf = subg.get_velodrome_pool_tvl(c)\n",
    "                elif program['protocol'] == 'hop':\n",
    "                        sdf = subg.get_hop_pool_tvl(c)\n",
    "                sdf['start_date'] = program['start_date']\n",
    "                sdf['end_date'] = program['end_date']\n",
    "                sdf['program_name'] = program['program_name']\n",
    "                sdf['protocol'] = program['og_protocol']\n",
    "\n",
    "                sdf['token_value'] = sdf['token_value'].fillna(0)\n",
    "                sdf['usd_value'] = sdf['usd_value'].fillna(0)\n",
    "                dfs_sub.append(sdf)\n",
    "df_df_sub = pd.concat(dfs_sub)\n",
    "# display(df_df_sub[df_df_sub['program_name'].str.contains('Velo')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21088526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_df_sub.sort_values(by='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df_comb = pd.concat([df_dfl, df_df_sub])\n",
    "# display(df_df_comb)\n",
    "df_df_comb['start_date'] = pd.to_datetime(df_df_comb['start_date'])\n",
    "df_df_comb['end_date'] = pd.to_datetime(df_df_comb['end_date'])\n",
    "df_df_comb['date'] = pd.to_datetime(df_df_comb['date'])\n",
    "# display(df_df_comb)\n",
    "\n",
    "# Make sure datatypes are clean\n",
    "df_df_comb['token_value'] = df_df_comb['token_value'].astype('float64')\n",
    "df_df_comb['usd_value'] = df_df_comb['usd_value'].astype('float64')\n",
    "\n",
    "#create an extra day to handle for tokens dropping to 0\n",
    "#this is a temp fix - longer term also: Get max of a token x date and do date + 1 = 0 (i.e. weth to eth flips)\n",
    "# find intermediate gaps. Call it a 0 flow in the in-between dates (i.e. pooltogether)\n",
    "df_df_shift = df_df_comb.copy()\n",
    "df_df_shift['date'] = df_df_shift['date'] + timedelta(days=1)\n",
    "df_df_shift['token_value'] = 0\n",
    "df_df_shift['usd_value'] = 0\n",
    "\n",
    "#merge back in\n",
    "df_df = pd.concat([df_df_comb,df_df_shift])\n",
    "df_df = df_df[df_df['date'] <= pd.to_datetime(\"today\") ]\n",
    "\n",
    "# Group - Exclude End Date since this is often null and overwritting could be weird, especially if we actually know an end date\n",
    "df_df['start_date'] = df_df['start_date'].fillna( pd.to_datetime(\"today\").floor('d') )\n",
    "#Generate End Date Column\n",
    "df_df['end_date_30'] = df_df['end_date'].fillna(pd.to_datetime(\"today\")).dt.floor('d') + timedelta(days = 30)\n",
    "\n",
    "df_df = df_df.groupby(['date','token','protocol','start_date','end_date_30','program_name']).sum(numeric_only=True).reset_index()\n",
    "\n",
    "# display(\n",
    "#         df_df[(df_df['protocol']=='revert-compoundor') & (df_df['date'] == '2022-11-09')] \n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9eb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = df_df.copy()#merge(cg_df, on=['date','token'],how='inner')\n",
    "\n",
    "# data_df = data_df[data_df['token_value'] > 0] #Exclude this, so we can read flows\n",
    "\n",
    "data_df.sort_values(by='date',inplace=True)\n",
    "# data_df['token_value'] = data_df['token_value'].replace(0, np.nan) #keep zeroes\n",
    "data_df['price_usd'] = data_df['usd_value']/data_df['token_value']\n",
    "\n",
    "data_df['rank_desc'] = data_df.groupby(['protocol', 'program_name', 'token'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "\n",
    "data_df.sort_values(by='date',inplace=True)\n",
    "\n",
    "last_df = data_df[data_df['rank_desc'] == 1]\n",
    "last_df = last_df.rename(columns={'price_usd':'last_price_usd'})\n",
    "last_df = last_df[['token','protocol','program_name','last_price_usd']]\n",
    "# display(last_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.merge(last_df, on=['token','protocol','program_name'], how='left')\n",
    "\n",
    "data_df['last_token_value'] = data_df.groupby(['token','protocol', 'program_name'])['token_value'].shift(1)\n",
    "\n",
    "data_df['last_price_usd'] = data_df.groupby(['token','protocol', 'program_name'])['price_usd'].shift(1)\n",
    "\n",
    "# If first instnace of token, make sure there's no price diff\n",
    "data_df['last_price_usd'] = data_df[['last_price_usd', 'price_usd']].bfill(axis=1).iloc[:, 0]\n",
    "#Forward fill if token drops off\n",
    "data_df['price_usd'] = data_df[['price_usd','last_price_usd']].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "data_df['last_token_value'] = data_df['last_token_value'].fillna(0)\n",
    "\n",
    "data_df['net_token_flow'] = data_df['token_value'] - data_df['last_token_value']\n",
    "data_df['net_price_change'] = data_df['price_usd'] - data_df['last_price_usd']\n",
    "\n",
    "data_df['net_dollar_flow'] = data_df['net_token_flow'] * data_df['price_usd']\n",
    "data_df['last_price_net_dollar_flow'] = data_df['net_token_flow'] * data_df['last_price_usd']\n",
    "\n",
    "data_df['net_price_stock_change'] = data_df['last_token_value'] * data_df['net_price_change']\n",
    "\n",
    "\n",
    "# display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e56fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter before start date\n",
    "data_df = data_df[data_df['date']>= data_df['start_date']]\n",
    "# filter lte end date + 30\n",
    "data_df = data_df[data_df['date']<= data_df['end_date_30']]\n",
    "data_df.drop('end_date_30', axis=1, inplace=True)\n",
    "\n",
    "if not os.path.exists(prepend + \"csv_outputs\"):\n",
    "        os.mkdir(prepend + \"csv_outputs\")\n",
    "data_df.to_csv(prepend + 'csv_outputs/' + 'tvl_flows_by_token.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df[data_df['protocol']=='perpetual-protocol'].sort_values(by='date')\n",
    "# data_df.fillna(0)\n",
    "# data_df.sample(5)\n",
    "# data_df[(data_df['protocol'] == 'pooltogether') & (data_df['date'] >= '2022-10-06') & (data_df['date'] <= '2022-10-12')].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "netdf_df = data_df[['date','protocol','program_name','net_dollar_flow','net_price_stock_change','last_price_net_dollar_flow','usd_value']]\n",
    "\n",
    "netdf_df = netdf_df.groupby(['date','protocol','program_name']).sum(['net_dollar_flow','net_price_stock_change','last_price_net_dollar_flow','usd_value'])\n",
    "\n",
    "# reset & get program data\n",
    "netdf_df.reset_index(inplace=True)\n",
    "\n",
    "netdf_df['tvl_change'] = netdf_df['usd_value'] - netdf_df.groupby(['protocol', 'program_name'])['usd_value'].shift(1)\n",
    "netdf_df['error'] = netdf_df['tvl_change'] - (netdf_df['net_dollar_flow'] + netdf_df['net_price_stock_change'])\n",
    "\n",
    "cumul_cols = ['net_dollar_flow','last_price_net_dollar_flow','net_price_stock_change']\n",
    "for c in cumul_cols:\n",
    "        netdf_df['cumul_' + c] = netdf_df.groupby(['protocol', 'program_name'])[c].cumsum()\n",
    "        # netdf_df['cumul_last_price_net_dollar_flow'] = netdf_df.groupby(['protocol', 'program_name'])['last_price_net_dollar_flow'].cumsum()\n",
    "        # netdf_df['cumul_net_price_stock_change'] = netdf_df.groupby(['protocol', 'program_name'])['net_price_stock_change'].cumsum()\n",
    "\n",
    "# display(netdf_df)\n",
    "\n",
    "# Bring Program info Back In\n",
    "netdf_df = netdf_df.merge(protocols[['include_in_summary','program_name','protocol','op_source','start_date','end_date','num_op']], on=['program_name','protocol'])\n",
    "\n",
    "#For Summary\n",
    "if_ended_cols = ['net_dollar_flow','last_price_net_dollar_flow']\n",
    "new_ended_cols = []\n",
    "for e in if_ended_cols:\n",
    "        netdf_df['cumul_' + e + '_if_ended'] = netdf_df[~netdf_df['end_date'].isna()].groupby(['protocol', 'program_name'])[e].cumsum()\n",
    "        new_ended_cols.append('cumul_' + e + '_if_ended')\n",
    "#\n",
    "# print(new_ended_cols)\n",
    "# display(netdf_df[netdf_df['protocol'] == 'revert-compoundor'])\n",
    "\n",
    "for d in date_cols:\n",
    "        netdf_df[d] = pd.to_datetime(netdf_df[d])\n",
    "\n",
    "# check info at program end\n",
    "# display(program_end_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cols = ['cumul_net_dollar_flow','cumul_last_price_net_dollar_flow','cumul_net_price_stock_change','num_op']\n",
    "\n",
    "# for sc in summary_cols:\n",
    "#         netdf_df[sc] = netdf_df[sc].astype('int64')\n",
    "summary_cols = summary_cols + new_ended_cols\n",
    "# print(summary_cols)\n",
    "program_end_df = netdf_df[pd.to_datetime(netdf_df['date']) == pd.to_datetime(netdf_df['end_date'])].groupby(['protocol', 'program_name']).sum(numeric_only=True)\n",
    "program_end_df.reset_index(inplace=True)\n",
    "# display(program_end_df)\n",
    "\n",
    "# display(program_end_df)\n",
    "for s in summary_cols:\n",
    "        s_new = s+'_at_program_end'\n",
    "        program_end_df = program_end_df.rename(columns={s:s_new})\n",
    "        netdf_df = netdf_df.merge(program_end_df[['protocol','program_name',s_new]], on=['protocol','program_name'], how = 'left')\n",
    "\n",
    "# netdf_df['cumul_net_dollar_flow_at_program_end'] = netdf_df[is_program_end].groupby(['protocol', 'program_name']).sum(['cumul_net_dollar_flow'])\n",
    "# netdf_df['cumul_last_price_net_dollar_flow_at_program_end'] = netdf_df[netdf_df['date'] == netdf_df['end_date']]['last_price_net_dollar_flow'].groupby(['protocol', 'program_name']).cumsum()\n",
    "# netdf_df['cumul_net_price_stock_change_at_program_end'] = netdf_df[netdf_df['date'] == netdf_df['end_date']]['net_price_stock_change'].groupby(['protocol', 'program_name']).cumsum()\n",
    "\n",
    "netdf_df['program_rank_desc'] = netdf_df.groupby(['protocol', 'program_name'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "\n",
    "# netdf_df.loc[ netdf_df['end_date'] == pd.to_datetime(\"2000-01-01\"), 'end_date' ] == pd.to_datetime(\"1900-01-01\")\n",
    "\n",
    "# np.where( netdf_df['end_date'] <= pd.to_datetime(\"2000-01-01\") , pd.NaT , netdf_df['end_date'] )\n",
    "# display(netdf_df[netdf_df['protocol'] == 'hundred-finance'].sort_values(by='program_rank_desc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb142e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# netdf_df[(netdf_df['date'] >= '2022-10-06') & (netdf_df['date'] <= '2022-10-12')].tail(10)\n",
    "netdf_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3721d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "during_str = 'During Program'\n",
    "post_str = 'Post-Program'\n",
    "\n",
    "netdf_df['period'] = np.where(\n",
    "        netdf_df['date'] > netdf_df['end_date'], post_str, during_str\n",
    "        )\n",
    "if not os.path.exists(prepend + \"csv_outputs\"):\n",
    "        os.mkdir(prepend + \"csv_outputs\")\n",
    "netdf_df.to_csv(prepend + 'csv_outputs/op_summer_daily_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_data_df = netdf_df[netdf_df['program_rank_desc'] == 1]\n",
    "latest_data_df['date'] = latest_data_df['date'].dt.date\n",
    "# latest_data_df['days_since_program_end'] \n",
    "# latest_data_df.loc[latest_data_df['end_date'] != '', 'days_since_program_end'] = \\\n",
    "#         pd.to_datetime(latest_data_df['end_date']) \\\n",
    "#         - pd.to_datetime(latest_data_df['date'])\n",
    "\n",
    "latest_data_df['days_since_program_end'] = \\\n",
    "        np.where(latest_data_df['end_date'] != '',\n",
    "        pd.to_datetime(latest_data_df['end_date']) \\\n",
    "        - pd.to_datetime(latest_data_df['date']) \\\n",
    "        , \\\n",
    "        pd.to_datetime(latest_data_df['date']) \\\n",
    "        - pd.to_datetime(latest_data_df['start_date']) \\\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate agg summary df\n",
    "season_summary = latest_data_df[latest_data_df['include_in_summary'] == 1].copy()\n",
    "\n",
    "season_summary_s0_no_perp = season_summary[(season_summary['op_source'] == 'Gov Fund - Phase 0') \\\n",
    "                                                & (season_summary['protocol'] != 'perpetual-protocol')]\n",
    "\n",
    "season_summary_s0_no_perp['op_source'] = 'Gov Fund - Phase 0 (Excl. Perp)'\n",
    "\n",
    "season_summary = pd.concat([season_summary, season_summary_s0_no_perp])\n",
    "\n",
    "season_summary = season_summary.groupby('op_source').sum()\n",
    "season_summary.reset_index(inplace=True)\n",
    "season_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdfaaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [latest_data_df, season_summary]\n",
    "latest_data_df.name = 'latest_data_df'\n",
    "season_summary.name = 'season_summary'\n",
    "\n",
    "for df in df_list:\n",
    "\n",
    "        df['cumul_flows_per_op_at_program_end'] = df['cumul_net_dollar_flow_at_program_end'] / df['num_op_at_program_end']\n",
    "        df['cumul_flows_per_op_latest'] = df['cumul_net_dollar_flow'] / df['num_op']\n",
    "\n",
    "        df['last_price_net_dollar_flows_per_op_at_program_end'] = df['cumul_last_price_net_dollar_flow_at_program_end'] / df['num_op_at_program_end']\n",
    "        df['last_price_net_dollar_flows_per_op_latest'] = df['cumul_last_price_net_dollar_flow'] / df['num_op']\n",
    "\n",
    "        df['flows_retention'] = \\\n",
    "                        df['cumul_net_dollar_flow_if_ended'] / df['cumul_net_dollar_flow_at_program_end'] \\\n",
    "                        * np.where(df['cumul_net_dollar_flow'] < 0, -1, 1)\n",
    "        df['last_price_net_dollar_flows_retention'] = \\\n",
    "                        df['cumul_last_price_net_dollar_flow_if_ended'] / df['cumul_last_price_net_dollar_flow_at_program_end'] \\\n",
    "                        * np.where(df['cumul_last_price_net_dollar_flow'] < 0, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74469ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    #get df name\n",
    "    col_list = [\n",
    "        'date','program_name', 'num_op','period','op_source','start_date','end_date'\n",
    "        ,'cumul_net_dollar_flow_at_program_end'\n",
    "        ,'cumul_net_dollar_flow'\n",
    "        ,'cumul_flows_per_op_at_program_end','cumul_last_price_net_dollar_flow_at_program_end'\n",
    "        ,'cumul_flows_per_op_latest', 'cumul_last_price_net_dollar_flow'\n",
    "        , 'last_price_net_dollar_flows_per_op_at_program_end','last_price_net_dollar_flows_per_op_latest'\n",
    "        ,'flows_retention', 'last_price_net_dollar_flows_retention'\n",
    "    ]\n",
    "    summary_exclude_list = ['date','program_name','period','start_date','end_date']\n",
    "    sort_cols = ['Start','# OP']\n",
    "\n",
    "    if df.name == 'latest_data_df':\n",
    "        html_name = 'op_summer_latest_stats'\n",
    "    elif df.name == 'season_summary':\n",
    "        html_name = 'season_summary_stats'\n",
    "        sort_cols = ['Source','# OP']\n",
    "        col_list = [x for x in col_list if x not in summary_exclude_list]\n",
    "    else:\n",
    "        html_name = 'other'\n",
    "\n",
    "    df_format = df.copy()\n",
    "    new_cols = df_format.columns\n",
    "    drop_cols = ['net_dollar_flow',\n",
    "        'net_price_stock_change', 'last_price_net_dollar_flow', 'usd_value',\n",
    "        'tvl_change', 'error'\n",
    "        ]\n",
    "    new_cols = new_cols.drop(drop_cols)\n",
    "    # print(new_cols)\n",
    "    df_format = df_format[new_cols]\n",
    "\n",
    "    df_format['num_op'] = df_format['num_op'].apply(lambda x: '{0:,.0f}'.format(x) if not pd.isna(x) else x )\n",
    "    df_format['flows_retention'] = df_format['flows_retention'].apply(lambda x: '{:,.1%}'.format(x) if not pd.isna(x) else x )\n",
    "    df_format['last_price_net_dollar_flows_retention'] = df_format['last_price_net_dollar_flows_retention'].apply(lambda x: '{:,.1%}'.format(x) if not pd.isna(x) else x )\n",
    "\n",
    "    df_format = df_format[col_list]\n",
    "    df_format = df_format.reset_index(drop=True)\n",
    "\n",
    "    if not os.path.exists(prepend + \"csv_outputs\"):\n",
    "        os.mkdir(prepend + \"csv_outputs\")\n",
    "    df_format.to_csv(prepend + 'csv_outputs/' + html_name + '.csv', index=False)\n",
    "\n",
    "    format_cols = [\n",
    "        'cumul_flows_per_op_at_program_end','cumul_flows_per_op_latest','last_price_net_dollar_flows_per_op_at_program_end','last_price_net_dollar_flows_per_op_latest']\n",
    "    format_mil_cols = [\n",
    "        'cumul_net_dollar_flow', 'cumul_last_price_net_dollar_flow',\n",
    "        'cumul_net_dollar_flow_at_program_end',\n",
    "        'cumul_last_price_net_dollar_flow_at_program_end'\n",
    "    ]\n",
    "    for f in format_cols:\n",
    "        df_format[f] = df_format[f].apply(lambda x: '${0:,.2f}'.format(x) if not pd.isna(x) else x )\n",
    "    for fm in format_mil_cols:\n",
    "        df_format[fm] = df_format[fm].apply(lambda x: '${0:,.2f}M'.format(x/1e6) if not pd.isna(x) else x )\n",
    "\n",
    "\n",
    "    df_format = df_format.rename(columns={\n",
    "        'date':'Date', 'program_name':'Program', 'num_op': '# OP'\n",
    "        ,'period': 'Period','op_source': 'Source','start_date':'Start','end_date':'End'\n",
    "        ,'cumul_net_dollar_flow_at_program_end':'Net Flows (at End Date)'\n",
    "        ,'cumul_net_dollar_flow':'Net Flows (End + 30)'\n",
    "        ,'cumul_last_price_net_dollar_flow_at_program_end':'Net Flows @ Current Prices (End + 30)'\n",
    "        ,'cumul_flows_per_op_at_program_end': 'Net Flows per OP (at End Date)'\n",
    "        ,'cumul_flows_per_op_latest': 'Net Flows per OP (End + 30)'\n",
    "        ##\n",
    "        ,'cumul_last_price_net_dollar_flow':'Net Flows @ Current Prices (End + 30)'\n",
    "        ,'last_price_net_dollar_flows_per_op_at_program_end': 'Net Flows per OP @ Current Prices (at End Date)'\n",
    "        ,'last_price_net_dollar_flows_per_op_latest': 'Net Flows per OP @ Current Prices (End + 30)'\n",
    "        ,'flows_retention' : 'Net Flows Retained'\n",
    "        ,'last_price_net_dollar_flows_retention' : 'Net Flows Retained @ Current Prices'\n",
    "    })\n",
    "    df_format = df_format.fillna('')\n",
    "    df_format = df_format.reset_index(drop=True)\n",
    "    df_format = df_format.sort_values(by=sort_cols, ascending = [True,False])\n",
    "\n",
    "    pd_html = pu.generate_html(df_format)\n",
    "    open(prepend + \"img_outputs/app/\" + html_name + \".html\", \"w\").write(pd_html)\n",
    "\n",
    "\n",
    "# latest_data_df_format.to_html('op_summer_latest_stats.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee270a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for Charts\n",
    "\n",
    "netdf_df = netdf_df[netdf_df['date'] <= pd.to_datetime(\"today\").floor('d')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(netdf_df, x=\"date\", y=\"net_dollar_flow\", color=\"program_name\", \\\n",
    "             title=\"Daily Net Dollar Flow since Program Announcement\",\\\n",
    "            labels={\n",
    "                     \"date\": \"Day\",\n",
    "                     \"net_dollar_flow\": \"Net Dollar Flow (N$F)\"\n",
    "                 }\n",
    "            )\n",
    "fig.update_layout(\n",
    "    legend_title=\"App Name\"\n",
    ")\n",
    "fig.update_layout(yaxis_tickprefix = '$')\n",
    "fig.write_image(prepend + \"img_outputs/svg/daily_ndf.svg\")\n",
    "fig.write_image(prepend + \"img_outputs/png/daily_ndf.png\")\n",
    "fig.write_html(prepend + \"img_outputs/daily_ndf.html\", include_plotlyjs='cdn')\n",
    "\n",
    "# cumul_fig = px.area(netdf_df, x=\"date\", y=\"cumul_net_dollar_flow\", color=\"program_name\", \\\n",
    "#              title=\"Cumulative Dollar Flow since Program Announcement\",\\\n",
    "#                    labels={\n",
    "#                      \"date\": \"Day\",\n",
    "#                      \"cumul_net_dollar_flow\": \"Cumulative Net Dollar Flow (N$F)\"\n",
    "#                  }\n",
    "#             ,areamode='group')\n",
    "# cumul_fig.update_layout(yaxis_tickprefix = '$')\n",
    "# cumul_fig_app.show()\n",
    "\n",
    "\n",
    "cumul_fig = go.Figure()\n",
    "proto_names = netdf_df['program_name'].drop_duplicates()\n",
    "# print(proto_names)\n",
    "for p in proto_names:\n",
    "    cumul_fig.add_trace(go.Scatter(x=netdf_df[netdf_df['program_name'] == p]['date'] \\\n",
    "                                   , y=netdf_df[netdf_df['program_name'] == p]['cumul_net_dollar_flow'] \\\n",
    "                                    ,name = p\\\n",
    "                                  ,fill='tozeroy')) # fill down to xaxis\n",
    "\n",
    "cumul_fig.update_layout(yaxis_tickprefix = '$')\n",
    "cumul_fig.update_layout(\n",
    "    title=\"Cumulative Net Dollar Flow since Program Announcement\",\n",
    "    xaxis_title=\"Day\",\n",
    "    yaxis_title=\"Cumulative Net Dollar Flow (N$F)\",\n",
    "    legend_title=\"App Name\",\n",
    "#     color_discrete_map=px.colors.qualitative.G10\n",
    ")\n",
    "cumul_fig.write_image(prepend + \"img_outputs/svg/cumul_ndf.svg\") #prepend + \n",
    "cumul_fig.write_image(prepend + \"img_outputs/png/cumul_ndf.png\") #prepend + \n",
    "cumul_fig.write_html(prepend + \"img_outputs/cumul_ndf.html\", include_plotlyjs='cdn')\n",
    "\n",
    "\n",
    "fig_last = go.Figure()\n",
    "proto_names = netdf_df['program_name'].drop_duplicates()\n",
    "# print(proto_names)\n",
    "for p in proto_names:\n",
    "    fig_last.add_trace(go.Scatter(x=netdf_df[netdf_df['program_name'] == p]['date'] \\\n",
    "                                   , y=netdf_df[netdf_df['program_name'] == p]['cumul_last_price_net_dollar_flow'] \\\n",
    "                                    ,name = p\\\n",
    "                                  ,fill='tozeroy')) # fill down to xaxis\n",
    "\n",
    "fig_last.update_layout(yaxis_tickprefix = '$')\n",
    "fig_last.update_layout(\n",
    "    title=\"Cumulative Net Dollar Flow since Program Announcement (At Most Recent Token Price)\",\n",
    "    xaxis_title=\"Day\",\n",
    "    yaxis_title=\"Cumulative Net Dollar Flow (N$F) - At Most Recent Price\",\n",
    "    legend_title=\"App Name\",\n",
    "#     color_discrete_map=px.colors.qualitative.G10\n",
    ")\n",
    "fig_last.write_image(prepend + \"img_outputs/svg/cumul_ndf_last_price.svg\")\n",
    "fig_last.write_image(prepend + \"img_outputs/png/cumul_ndf_last_price.png\")\n",
    "fig_last.write_html(prepend + \"img_outputs/cumul_ndf_last_price.html\", include_plotlyjs='cdn')\n",
    "# cumul_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program-Specific Charts\n",
    "\n",
    "value_list = ['cumul_net_dollar_flow','cumul_last_price_net_dollar_flow']\n",
    "\n",
    "for val in value_list:\n",
    "  if val == 'cumul_last_price_net_dollar_flow':\n",
    "    postpend = \" - At Last Price\"\n",
    "    folder_path = \"/last_price\"\n",
    "  else:\n",
    "    postpend = \"\"\n",
    "    folder_path = \"\"\n",
    "  proto_names = netdf_df['program_name'].drop_duplicates()\n",
    "  # print(proto_names)\n",
    "  for p in proto_names:\n",
    "      cumul_fig_app = go.Figure()\n",
    "      p_df = netdf_df[netdf_df['program_name'] == p]\n",
    "      # cumul_fig_app = px.area(p_df, x=\"date\", y=\"cumul_net_dollar_flow\", color=\"period\")\n",
    "      \n",
    "      during_df = p_df[p_df['period'] == during_str]\n",
    "      cumul_fig_app.add_trace(go.Scatter(x= during_df['date'] \\\n",
    "                                    , y= during_df[val] \\\n",
    "                                      , name = during_str \\\n",
    "                                    ,fill='tozeroy')) # fill down to xaxis\n",
    "      \n",
    "      post_df = p_df[p_df['period'] == post_str]\n",
    "      cumul_fig_app.add_trace(go.Scatter(x= post_df['date'] \\\n",
    "                                    , y= post_df[val] \\\n",
    "                                      , name = post_str \\\n",
    "                                    ,fill='tozeroy')) # fill down to xaxis\n",
    "\n",
    "      cumul_fig_app.update_layout(yaxis_tickprefix = '$')\n",
    "      cumul_fig_app.update_layout(\n",
    "          title=p + \"<br><sup>Cumulative Net Dollar Flow since Program Announcement, Until Program End + 30 Days\" + postpend + \"</sup>\",\n",
    "          xaxis_title=\"Day\",\n",
    "          yaxis_title=\"Cumulative Net Dollar Flow (N$F)\",\n",
    "          legend_title=\"Period\",\n",
    "      #     color_discrete_map=px.colors.qualitative.G10\n",
    "      )\n",
    "      \n",
    "      if not os.path.exists(prepend + \"img_outputs/app\" + folder_path):\n",
    "        os.mkdir(prepend + \"img_outputs/app\" + folder_path)\n",
    "      if not os.path.exists(prepend + \"img_outputs/app\" + folder_path + \"/svg\"):\n",
    "        os.mkdir(prepend + \"img_outputs/app\" + folder_path + \"/svg\")\n",
    "      if not os.path.exists(prepend + \"img_outputs/app\" + folder_path + \"/png\"):\n",
    "        os.mkdir(prepend + \"img_outputs/app/\" + folder_path + \"/png\")\n",
    "      \n",
    "      p_file = p\n",
    "      p_file = p_file.replace(' ','_')\n",
    "      p_file = p_file.replace(':','')\n",
    "      p_file = p_file.replace('/','-')\n",
    "      cumul_fig_app.write_image(prepend + \"img_outputs/app\" + folder_path + \"/svg/cumul_ndf_\" + p_file + \".svg\") #prepend + \n",
    "      cumul_fig_app.write_image(prepend + \"img_outputs/app\" + folder_path + \"/png/cumul_ndf_\" + p_file + \".png\") #prepend + \n",
    "      cumul_fig_app.write_html(prepend + \"img_outputs/app\" + folder_path + \"/cumul_ndf_\" + p_file + \".html\", include_plotlyjs='cdn')\n",
    "      # cumul_fig_app.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()\n",
    "cumul_fig.show()\n",
    "print(\"yay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter nbconvert --to python optimism_app_net_flows.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "568c45baba86190bf65a5d0b3302bdb9b067c88c2eaacc48373a8c9b6714aa9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
