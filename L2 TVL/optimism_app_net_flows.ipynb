{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas\n",
    "# ! pip install requests\n",
    "# ! pip install plotly\n",
    "# ! pip install datetime\n",
    "# ! pip install os\n",
    "# ! pip freeze = requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as r\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import optimism_subgraph_tvls as subg\n",
    "import defillama_utils as dfl\n",
    "import pandas_utils as pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "if 'L2 TVL' in pwd:\n",
    "    prepend = ''\n",
    "else:\n",
    "    prepend = 'L2 TVL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocol Incentive Start Dates\n",
    "# Eventually, move this to its own file / csv\n",
    "protocols = pd.DataFrame(\n",
    "    [\n",
    "        # name, incentive start date\n",
    "            # General Programs\n",
    "             ['velodrome',  3000000,          '2022-07-13',   '2022-11-17',   '', 'Partner Fund', 'defillama','']\n",
    "            ,['pooltogether',   450000, '2022-07-22',   '', '', 'Partner Fund', 'defillama','']\n",
    "            ,['lyra',   3000000,               '2022-08-02',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['rubicon',    900000,            '2022-07-15',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['perpetual-protocol', 9000000, '2022-07-14',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['thales', 900000,             '2022-07-15',   '',   '', 'Gov Fund - Phase 0', 'defillama',''] #TVL not relevant\n",
    "            ,['aave-v3',    5000000,            '2022-08-04',   '2022-11-04',   'Aave - Liquidity Mining', 'Partner Fund', 'defillama','']\n",
    "            ,['wepiggy',    300000,            '2022-08-03',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['stargate',   1000000,           '2022-08-05',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['pika-protocol',  9000000,      '2022-08-29',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['pickle', 200000,             '2022-09-09',   '',   '', 'Gov Fund - Season 1', 'defillama','']\n",
    "            ,['aelin',  900000,              '2022-09-12',   '2022-09-14',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['polynomial-protocol',    900000, '2022-09-14',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['xtoken', 900000,             '2022-09-19',   '',   '', 'Gov Fund - Season 1', 'defillama','']\n",
    "            ,['hop-protocol',   1000000,       '2022-09-22',   '',   '', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['beethoven-x',    500000,        '2022-09-29',   '',   '', 'Gov Fund - Season 1', 'defillama','']\n",
    "            ,['revert-compoundor',  240000,  '2022-11-03',   '',   '', 'Gov Fund - Season 2', 'defillama','']\n",
    "            ,['beefy',  650000*.5,              '2022-10-24',   '',   '', 'Gov Fund - Season 1', 'defillama',''] #Incenvitived VELO - Seems like Beefy boost started Oct 24? Unclear\n",
    "            ,['hundred-finance',    300000,    '2022-11-28',   '',   '', 'Gov Fund - Season 1', 'defillama','']\n",
    "            #Uniswap LM Program\n",
    "            ,['uniswap-v3', 150000,         '2022-10-26',   '2022-11-21',   'Uniswap LM - Phase 1', 'Gov Fund - Phase 0', 'defillama','']\n",
    "            ,['arrakis-finance',    50000,    '2022-10-26',   '2022-11-21',   'Uniswap LM - Phase 1', 'Gov Fund - Phase 0','defillama','']\n",
    "            ,['gamma',    50000,              '2022-10-26',   '2022-11-21',   'Uniswap LM - Phase 1', 'Gov Fund - Phase 0','defillama','']\n",
    "            ,['xtoken',    50000,             '2022-10-26',   '2022-11-21',   'Uniswap LM - Phase 1', 'Gov Fund - Phase 0','defillama','']\n",
    "            # Other DEX Programs\n",
    "            ,['synthetix',  9000000,    '2022-08-25',   '',   'sUSD & sETH: Curve', 'Gov Fund - Phase 0', 'subgraph-curve',['0x7bc5728bc2b59b45a58d9a576e2ffc5f0505b35e','0x061b87122ed14b9526a813209c8a59a633257bab']] # susd/usd + seth/eth Curve incentives started\n",
    "            ,['l2dao',  300000,    '2022-07-20',   '2022-08-22',   'L2DAO/OP: Velodrome', 'Gov Fund - Phase 0', 'subgraph-velodrome',['0xfc77e39de40e54f820e313039207dc850e4c9e60']] # l2dao/op incentives - estimating end date based on last distribution to Velo gauge + 7 days\n",
    "            ,['beefy',  650000*.35,    '2022-09-13',   '',   'BIFI/OP: Velodrome', 'Gov Fund - Phase 0', 'subgraph-velodrome',['0x81f638e5d063618fc5f6a976e48e9b803b3240c0']] # bifi/op incentives\n",
    "            ]\n",
    "        , columns = ['protocol','num_op','start_date', 'end_date','name', 'op_source', 'data_source','contracts']\n",
    "    )\n",
    "# print(protocols[0])\n",
    "protocols['id_format'] = protocols['protocol'].str.replace('-',' ').str.title()\n",
    "\n",
    "# protocols['program_name'] = np.where( protocols['name'] == '', protocols['id_format'], protocols['name'])\n",
    "protocols['coalesce'] = np.where( protocols['name'] == ''\n",
    "                                    , protocols['id_format']\n",
    "                                    , protocols['name']\n",
    "                                    )\n",
    "# Get count by coalesced name\n",
    "pcounts = pd.DataFrame( protocols.groupby(['coalesce'])['name'].count() )\n",
    "pcounts = pcounts.rename(columns={'name':'count'})\n",
    "\n",
    "protocols = protocols.merge(pcounts, on = 'coalesce')\n",
    "\n",
    "\n",
    "protocols['program_name'] = np.where( ( (protocols['name'] == '') )#| (protocols['count'] == 1) )\n",
    "                                    , protocols['id_format']\n",
    "                                    , protocols['id_format'] + ' - ' + protocols['name']\n",
    "                                    )\n",
    "\n",
    "protocols = protocols.sort_values(by='start_date', ascending=True)\n",
    "                    \n",
    "# display(protocols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3399236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api_str = 'https://api.llama.fi/protocol/'\n",
    "\n",
    "\n",
    "prod = []\n",
    "s = r.Session()\n",
    "\n",
    "dfl_protocols = protocols[protocols['data_source'] == 'defillama'].copy()\n",
    "\n",
    "dfl_slugs = dfl_protocols[['protocol']].drop_duplicates()\n",
    "dfl_slugs = dfl_slugs.rename(columns={'protocol':'slug'})\n",
    "df_df = dfl.get_range(dfl_slugs[['slug']],['Optimism'])\n",
    "\n",
    "df_df = df_df.merge(dfl_protocols, on ='protocol')\n",
    "\n",
    "df_df = df_df[['date', 'token', 'token_value', 'usd_value', 'protocol', 'start_date','program_name']]\n",
    "\n",
    "# display(df_df)\n",
    "# for id, prot in dfl_protocols.iterrows():\n",
    "#     # print(api_str + prot['protocol'])\n",
    "#     try:\n",
    "#         tp = s.get(api_str + prot['protocol']).json()['chainTvls']['Optimism']\n",
    "#         # print(tp)\n",
    "#         ad = pd.json_normalize( tp['tokens'] )\n",
    "#         ad_usd = pd.json_normalize( tp['tokensInUsd'] )\n",
    "#         if not ad.empty:\n",
    "#             ad = pd.melt(ad,id_vars = ['date'])\n",
    "#             ad = ad.rename(columns={'variable':'token','value':'token_value'})\n",
    "#             ad_usd = pd.melt(ad_usd,id_vars = ['date'])\n",
    "#             ad_usd = ad_usd.rename(columns={'variable':'token','value':'usd_value'})\n",
    "#             ad = ad.merge(ad_usd,on=['date','token'])\n",
    "            \n",
    "#             ad['date'] = pd.to_datetime(ad['date'], unit ='s') #convert to days\n",
    "\n",
    "#             ad['token'] = ad['token'].str.replace('tokens.','', regex=False)\n",
    "#             ad['protocol'] = prot['protocol']\n",
    "#             ad['start_date'] = pd.to_datetime(prot['start_date'])\n",
    "#             ad['program_name'] = prot['program_name']\n",
    "#             # ad['date'] = ad['date'] - timedelta(days=1) #change to eod vs sod\n",
    "#             prod.append(ad)\n",
    "#             time.sleep(0.5)\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "# df_df = pd.concat(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "subg_protocols = protocols[protocols['data_source'].str.contains('subgraph')].copy()\n",
    "subg_protocols['og_protocol'] = subg_protocols['protocol']\n",
    "subg_protocols['protocol'] = subg_protocols['data_source'].str.replace('subgraph-','')\n",
    "# display(subg_protocols)\n",
    "\n",
    "dfs_sub = []\n",
    "for index, program in subg_protocols.iterrows():\n",
    "        for c in program['contracts']:\n",
    "                if program['protocol'] == 'curve':\n",
    "                        sdf = subg.get_curve_pool_tvl(c)\n",
    "                elif program['protocol'] == 'velodrome':\n",
    "                        sdf = subg.get_velodrome_pool_tvl(c)\n",
    "                sdf['start_date'] = program['start_date']\n",
    "                sdf['program_name'] = program['program_name']\n",
    "                sdf['protocol'] = program['og_protocol']\n",
    "                sdf = sdf.fillna(0)\n",
    "                dfs_sub.append(sdf)\n",
    "df_df_sub = pd.concat(dfs_sub)\n",
    "# display(df_df_sub.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21088526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_df_sub.sort_values(by='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df = pd.concat([df_df, df_df_sub])\n",
    "df_df['start_date'] = pd.to_datetime(df_df['start_date'])\n",
    "# display(df_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ccb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_df\n",
    "# df_df = df_df.fillna(0)\n",
    "# display(df_df)\n",
    "# for prot in protocols:\n",
    "#         print( prot[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9eb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = df_df.copy()#merge(cg_df, on=['date','token'],how='inner')\n",
    "\n",
    "data_df = data_df[data_df['token_value'] > 0]\n",
    "\n",
    "data_df.sort_values(by='date',inplace=True)\n",
    "data_df['token_value'] = data_df['token_value'].replace(0, np.nan)\n",
    "data_df['price_usd'] = data_df['usd_value']/data_df['token_value']\n",
    "\n",
    "data_df['rank_desc'] = data_df.groupby(['protocol', 'program_name', 'token'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "\n",
    "data_df.sort_values(by='date',inplace=True)\n",
    "\n",
    "last_df = data_df[data_df['rank_desc'] == 1]\n",
    "last_df = last_df.rename(columns={'price_usd':'last_price_usd'})\n",
    "last_df = last_df[['token','protocol','program_name','last_price_usd']]\n",
    "# display(last_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.merge(last_df, on=['token','protocol','program_name'], how='left')\n",
    "\n",
    "data_df['last_token_value'] = data_df.groupby(['token','protocol', 'program_name'])['token_value'].shift(1)\n",
    "data_df['last_price_usd'] = data_df.groupby(['token','protocol', 'program_name'])['price_usd'].shift(1)\n",
    "data_df['last_token_value'] = data_df['last_token_value'].fillna(0)\n",
    "\n",
    "data_df['net_token_flow'] = data_df['token_value'] - data_df['last_token_value']\n",
    "data_df['net_price_change'] = data_df['price_usd'] - data_df['last_price_usd']\n",
    "\n",
    "data_df['net_dollar_flow'] = data_df['net_token_flow'] * data_df['price_usd']\n",
    "data_df['last_price_flow'] = data_df['net_token_flow'] * data_df['last_price_usd']\n",
    "\n",
    "data_df['net_price_stock_change'] = data_df['last_token_value'] * data_df['net_price_change']\n",
    "\n",
    "\n",
    "# display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df[data_df['protocol']=='perpetual-protocol'].sort_values(by='date')\n",
    "# data_df.fillna(0)\n",
    "# data_df.sample(5)\n",
    "# data_df[(data_df['protocol'] == 'pooltogether') & (data_df['date'] >= '2022-10-06') & (data_df['date'] <= '2022-10-12')].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "netdf_df = data_df[data_df['date']>= data_df['start_date']][['date','protocol','program_name','net_dollar_flow','net_price_stock_change','last_price_flow','usd_value']]\n",
    "\n",
    "netdf_df = netdf_df.groupby(['date','protocol','program_name']).sum(['net_dollar_flow','net_price_stock_change','last_price_flow','usd_value'])\n",
    "\n",
    "netdf_df['tvl_change'] = netdf_df['usd_value'] - netdf_df.groupby(['protocol', 'program_name'])['usd_value'].shift(1)\n",
    "netdf_df['error'] = netdf_df['tvl_change'] - (netdf_df['net_dollar_flow'] + netdf_df['net_price_stock_change'])\n",
    "\n",
    "\n",
    "netdf_df['cumul_net_dollar_flow'] = netdf_df['net_dollar_flow'].groupby(['protocol', 'program_name']).cumsum()\n",
    "netdf_df['cumul_last_price_net_dollar_flow'] = netdf_df['last_price_flow'].groupby(['protocol', 'program_name']).cumsum()\n",
    "netdf_df['cumul_net_price_stock_change'] = netdf_df['net_price_stock_change'].groupby(['protocol', 'program_name']).cumsum()\n",
    "# reset & get program data\n",
    "netdf_df.reset_index(inplace=True)\n",
    "\n",
    "netdf_df = netdf_df.merge(protocols[['program_name','protocol','op_source','start_date','end_date','num_op']], on=['program_name','protocol'])\n",
    "\n",
    "# check info at program end\n",
    "# display(program_end_df)\n",
    "\n",
    "summary_cols = ['cumul_net_dollar_flow','cumul_last_price_net_dollar_flow','cumul_net_price_stock_change']\n",
    "program_end_df = netdf_df[pd.to_datetime(netdf_df['date']) == pd.to_datetime(netdf_df['end_date'])].groupby(['protocol', 'program_name']).sum()\n",
    "program_end_df.reset_index(inplace=True)\n",
    "# display(program_end_df)\n",
    "for s in summary_cols:\n",
    "        s_new = s+'_at_program_end'\n",
    "        program_end_df = program_end_df.rename(columns={s:s_new})\n",
    "        netdf_df = netdf_df.merge(program_end_df[['protocol','program_name',s_new]], on=['protocol','program_name'], how = 'left')\n",
    "\n",
    "# netdf_df['cumul_net_dollar_flow_at_program_end'] = netdf_df[is_program_end].groupby(['protocol', 'program_name']).sum(['cumul_net_dollar_flow'])\n",
    "# netdf_df['cumul_last_price_net_dollar_flow_at_program_end'] = netdf_df[netdf_df['date'] == netdf_df['end_date']]['last_price_flow'].groupby(['protocol', 'program_name']).cumsum()\n",
    "# netdf_df['cumul_net_price_stock_change_at_program_end'] = netdf_df[netdf_df['date'] == netdf_df['end_date']]['net_price_stock_change'].groupby(['protocol', 'program_name']).cumsum()\n",
    "\n",
    "netdf_df['program_rank_desc'] = netdf_df.groupby(['protocol', 'program_name'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "\n",
    "# display(netdf_df[netdf_df['protocol'] == 'l2dao'].sort_values(by='program_rank_desc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb142e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# netdf_df[(netdf_df['date'] >= '2022-10-06') & (netdf_df['date'] <= '2022-10-12')].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3721d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "during_str = 'During Program'\n",
    "post_str = 'Post-Program'\n",
    "\n",
    "netdf_df['period'] = np.where(\n",
    "        netdf_df['date'] > netdf_df['end_date'], post_str, during_str\n",
    "        )\n",
    "netdf_df.to_csv('prepend + \"img_outputs/app/op_summer_daily_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_data_df = netdf_df[netdf_df['program_rank_desc'] == 1]\n",
    "latest_data_df['date'] = latest_data_df['date'].dt.date\n",
    "# latest_data_df['days_since_program_end'] \n",
    "# latest_data_df.loc[latest_data_df['end_date'] != '', 'days_since_program_end'] = \\\n",
    "#         pd.to_datetime(latest_data_df['end_date']) \\\n",
    "#         - pd.to_datetime(latest_data_df['date'])\n",
    "\n",
    "latest_data_df['days_since_program_end'] = \\\n",
    "        np.where(latest_data_df['end_date'] != '',\n",
    "        pd.to_datetime(latest_data_df['end_date']) \\\n",
    "        - pd.to_datetime(latest_data_df['date']) \\\n",
    "        , \\\n",
    "        pd.to_datetime(latest_data_df['date']) \\\n",
    "        - pd.to_datetime(latest_data_df['start_date']) \\\n",
    "        )\n",
    "\n",
    "latest_data_df['cumul_flows_per_op_at_program_end'] = latest_data_df['cumul_net_dollar_flow_at_program_end'] / latest_data_df['num_op']\n",
    "latest_data_df['cumul_flows_per_op_latest'] = latest_data_df['cumul_net_dollar_flow'] / latest_data_df['num_op']\n",
    "\n",
    "latest_data_df['last_price_flows_per_op_at_program_end'] = latest_data_df['cumul_last_price_net_dollar_flow_at_program_end'] / latest_data_df['num_op']\n",
    "latest_data_df['last_price_flows_per_op_latest'] = latest_data_df['cumul_last_price_net_dollar_flow'] / latest_data_df['num_op']\n",
    "\n",
    "latest_data_df['flows_retention'] = \\\n",
    "                latest_data_df['cumul_net_dollar_flow'] / latest_data_df['cumul_net_dollar_flow_at_program_end'] \\\n",
    "                * np.where(latest_data_df['cumul_net_dollar_flow'] < 0, -1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74469ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_data_df_format = latest_data_df.copy()\n",
    "new_cols = latest_data_df_format.columns\n",
    "drop_cols = ['net_dollar_flow',\n",
    "       'net_price_stock_change', 'last_price_flow', 'usd_value',\n",
    "       'tvl_change', 'error'\n",
    "       ]\n",
    "new_cols = new_cols.drop(drop_cols)\n",
    "# print(new_cols)\n",
    "latest_data_df_format = latest_data_df_format[new_cols]\n",
    "\n",
    "latest_data_df_format['num_op'] = latest_data_df_format['num_op'].apply(lambda x: '{0:,.0f}'.format(x) if not pd.isna(x) else x )\n",
    "latest_data_df_format['flows_retention'] = latest_data_df_format['flows_retention'].apply(lambda x: '{:,.1%}'.format(x) if not pd.isna(x) else x )\n",
    "\n",
    "format_cols = [\n",
    "    'cumul_net_dollar_flow','cumul_last_price_net_dollar_flow','cumul_net_price_stock_change',\n",
    "    'cumul_net_dollar_flow_at_program_end', 'cumul_last_price_net_dollar_flow_at_program_end', 'cumul_net_price_stock_change_at_program_end',\n",
    "    'cumul_flows_per_op_at_program_end','cumul_flows_per_op_latest','last_price_flows_per_op_at_program_end','last_price_flows_per_op_latest']\n",
    "for f in format_cols:\n",
    "    latest_data_df_format[f] = latest_data_df_format[f].apply(lambda x: '${0:,.2f}'.format(x) if not pd.isna(x) else x )\n",
    "\n",
    "\n",
    "latest_data_df_format[latest_data_df_format['protocol'] == 'xtoken'].tail(10)\n",
    "\n",
    "latest_data_df_format = latest_data_df_format[[\n",
    "    'date','program_name', 'num_op','period','op_source','start_date','end_date'\n",
    "    ,'cumul_net_dollar_flow_at_program_end'\n",
    "    ,'cumul_net_dollar_flow'\n",
    "    ,'cumul_flows_per_op_at_program_end','cumul_flows_per_op_latest', 'last_price_flows_per_op_at_program_end','last_price_flows_per_op_latest'\n",
    "    ,'flows_retention'\n",
    "]]\n",
    "latest_data_df_format = latest_data_df_format.rename(columns={\n",
    "    'date':'Date', 'program_name':'Program', 'num_op': '# OP'\n",
    "    ,'period': 'Period','op_source': 'Source','start_date':'Start','end_date':'End'\n",
    "    ,'cumul_net_dollar_flow_at_program_end':'Net Flows (at End Date)'\n",
    "    ,'cumul_net_dollar_flow':'Net Flows (Latest)'\n",
    "    ,'cumul_flows_per_op_at_program_end': 'Net Flows per OP (at End Date)'\n",
    "    ,'cumul_flows_per_op_latest': 'Net Flows per OP (Latest)'\n",
    "    ,'last_price_flows_per_op_at_program_end': 'Net Flows per OP @ Current Prices (at End Date)'\n",
    "    ,'last_price_flows_per_op_latest': 'Net Flows per OP @ Current Prices (Latest)'\n",
    "    ,'flows_retention' : 'Net Flows Retained'\n",
    "})\n",
    "latest_data_df_format = latest_data_df_format.fillna('')\n",
    "latest_data_df_format = latest_data_df_format.reset_index(drop=True)\n",
    "latest_data_df_format = latest_data_df_format.sort_values(by=['Start','# OP'], ascending = [True,False])\n",
    "pd_html = pu.generate_html(latest_data_df_format)\n",
    "\n",
    "open(prepend + \"img_outputs/app/op_summer_latest_stats.html\", \"w\").write(pd_html)\n",
    "latest_data_df_format.to_csv('prepend + \"img_outputs/app/op_summer_latest_stats.csv')\n",
    "\n",
    "# latest_data_df_format.to_html('op_summer_latest_stats.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(netdf_df, x=\"date\", y=\"net_dollar_flow\", color=\"program_name\", \\\n",
    "             title=\"Daily Net Dollar Flow since Program Announcement\",\\\n",
    "            labels={\n",
    "                     \"date\": \"Day\",\n",
    "                     \"net_dollar_flow\": \"Net Dollar Flow (N$F)\"\n",
    "                 }\n",
    "            )\n",
    "fig.update_layout(\n",
    "    legend_title=\"App Name\"\n",
    ")\n",
    "fig.update_layout(yaxis_tickprefix = '$')\n",
    "fig.write_image(prepend + \"img_outputs/svg/daily_ndf.svg\")\n",
    "fig.write_image(prepend + \"img_outputs/png/daily_ndf.png\")\n",
    "fig.write_html(prepend + \"img_outputs/daily_ndf.html\", include_plotlyjs='cdn')\n",
    "\n",
    "# cumul_fig = px.area(netdf_df, x=\"date\", y=\"cumul_net_dollar_flow\", color=\"program_name\", \\\n",
    "#              title=\"Cumulative Dollar Flow since Program Announcement\",\\\n",
    "#                    labels={\n",
    "#                      \"date\": \"Day\",\n",
    "#                      \"cumul_net_dollar_flow\": \"Cumulative Net Dollar Flow (N$F)\"\n",
    "#                  }\n",
    "#             ,areamode='group')\n",
    "# cumul_fig.update_layout(yaxis_tickprefix = '$')\n",
    "# cumul_fig_app.show()\n",
    "\n",
    "\n",
    "cumul_fig = go.Figure()\n",
    "proto_names = netdf_df['program_name'].drop_duplicates()\n",
    "# print(proto_names)\n",
    "for p in proto_names:\n",
    "    cumul_fig.add_trace(go.Scatter(x=netdf_df[netdf_df['program_name'] == p]['date'] \\\n",
    "                                   , y=netdf_df[netdf_df['program_name'] == p]['cumul_net_dollar_flow'] \\\n",
    "                                    ,name = p\\\n",
    "                                  ,fill='tozeroy')) # fill down to xaxis\n",
    "\n",
    "cumul_fig.update_layout(yaxis_tickprefix = '$')\n",
    "cumul_fig.update_layout(\n",
    "    title=\"Cumulative Net Dollar Flow since Program Announcement\",\n",
    "    xaxis_title=\"Day\",\n",
    "    yaxis_title=\"Cumulative Net Dollar Flow (N$F)\",\n",
    "    legend_title=\"App Name\",\n",
    "#     color_discrete_map=px.colors.qualitative.G10\n",
    ")\n",
    "cumul_fig.write_image(prepend + \"img_outputs/svg/cumul_ndf.svg\") #prepend + \n",
    "cumul_fig.write_image(prepend + \"img_outputs/png/cumul_ndf.png\") #prepend + \n",
    "cumul_fig.write_html(prepend + \"img_outputs/cumul_ndf.html\", include_plotlyjs='cdn')\n",
    "\n",
    "\n",
    "fig_last = go.Figure()\n",
    "proto_names = netdf_df['program_name'].drop_duplicates()\n",
    "# print(proto_names)\n",
    "for p in proto_names:\n",
    "    fig_last.add_trace(go.Scatter(x=netdf_df[netdf_df['program_name'] == p]['date'] \\\n",
    "                                   , y=netdf_df[netdf_df['program_name'] == p]['cumul_last_price_net_dollar_flow'] \\\n",
    "                                    ,name = p\\\n",
    "                                  ,fill='tozeroy')) # fill down to xaxis\n",
    "\n",
    "fig_last.update_layout(yaxis_tickprefix = '$')\n",
    "fig_last.update_layout(\n",
    "    title=\"Cumulative Net Dollar Flow since Program Announcement (At Most Recent Token Price)\",\n",
    "    xaxis_title=\"Day\",\n",
    "    yaxis_title=\"Cumulative Net Dollar Flow (N$F) - At Most Recent Price\",\n",
    "    legend_title=\"App Name\",\n",
    "#     color_discrete_map=px.colors.qualitative.G10\n",
    ")\n",
    "fig_last.write_image(prepend + \"img_outputs/svg/cumul_ndf_last_price.svg\")\n",
    "fig_last.write_image(prepend + \"img_outputs/png/cumul_ndf_last_price.png\")\n",
    "fig_last.write_html(prepend + \"img_outputs/cumul_ndf_last_price.html\", include_plotlyjs='cdn')\n",
    "# cumul_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program-Specific Charts\n",
    "\n",
    "proto_names = netdf_df['program_name'].drop_duplicates()\n",
    "# print(proto_names)\n",
    "for p in proto_names:\n",
    "    cumul_fig_app = go.Figure()\n",
    "    p_df = netdf_df[netdf_df['program_name'] == p]\n",
    "    # cumul_fig_app = px.area(p_df, x=\"date\", y=\"cumul_net_dollar_flow\", color=\"period\")\n",
    "    \n",
    "    during_df = p_df[p_df['period'] == during_str]\n",
    "    cumul_fig_app.add_trace(go.Scatter(x= during_df['date'] \\\n",
    "                                   , y= during_df['cumul_net_dollar_flow'] \\\n",
    "                                    , name = during_str \\\n",
    "                                  ,fill='tozeroy')) # fill down to xaxis\n",
    "    \n",
    "    post_df = p_df[p_df['period'] == post_str]\n",
    "    cumul_fig_app.add_trace(go.Scatter(x= post_df['date'] \\\n",
    "                                   , y= post_df['cumul_net_dollar_flow'] \\\n",
    "                                    , name = post_str \\\n",
    "                                  ,fill='tozeroy')) # fill down to xaxis\n",
    "\n",
    "    cumul_fig_app.update_layout(yaxis_tickprefix = '$')\n",
    "    cumul_fig_app.update_layout(\n",
    "        title=p + \": Cumulative Net Dollar Flow since Program Announcement\",\n",
    "        xaxis_title=\"Day\",\n",
    "        yaxis_title=\"Cumulative Net Dollar Flow (N$F)\",\n",
    "        legend_title=\"Period\",\n",
    "    #     color_discrete_map=px.colors.qualitative.G10\n",
    "    )\n",
    "    \n",
    "    if not os.path.exists(prepend + \"img_outputs/app\"):\n",
    "      os.mkdir(prepend + \"img_outputs/app\")\n",
    "    if not os.path.exists(prepend + \"img_outputs/app/svg\"):\n",
    "      os.mkdir(prepend + \"img_outputs/app/svg\")\n",
    "    if not os.path.exists(prepend + \"img_outputs/app/png\"):\n",
    "      os.mkdir(prepend + \"img_outputs/app/png\")\n",
    "    \n",
    "    p_file = p\n",
    "    p_file = p_file.replace(' ','_')\n",
    "    p_file = p_file.replace(':','')\n",
    "    p_file = p_file.replace('/','-')\n",
    "    cumul_fig_app.write_image(prepend + \"img_outputs/app/svg/cumul_ndf_\" + p_file + \".svg\") #prepend + \n",
    "    cumul_fig_app.write_image(prepend + \"img_outputs/app/png/cumul_ndf_\" + p_file + \".png\") #prepend + \n",
    "    cumul_fig_app.write_html(prepend + \"img_outputs/app/cumul_ndf_\" + p_file + \".html\", include_plotlyjs='cdn')\n",
    "    # cumul_fig_app.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()\n",
    "cumul_fig.show()\n",
    "print(\"yay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter nbconvert --to python optimism_app_net_flows.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('new-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d537a1638226190f579d6fbb68604c1b09ebc740a69df557abedb49ad78e592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
